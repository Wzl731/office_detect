{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¶æ„è½¯ä»¶æ£€æµ‹ - éšæœºæ£®æ—åˆ†ç±»å™¨ï¼ˆç»„åˆç‰¹å¾ç‰ˆï¼‰\n",
    "\n",
    "æœ¬notebookä½¿ç”¨éšæœºæ£®æ—ç®—æ³•å’Œç»„åˆç‰¹å¾å¯¹æ¶æ„è½¯ä»¶è¿›è¡Œæ£€æµ‹å’Œåˆ†ç±»ã€‚\n",
    "\n",
    "## å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# æœºå™¨å­¦ä¹ ç›¸å…³åº“\n",
    "from sklearn.model_selection import KFold  # KæŠ˜äº¤å‰éªŒè¯\n",
    "from sklearn.utils import shuffle  # æ•°æ®éšæœºæ‰“ä¹±\n",
    "from sklearn.ensemble import RandomForestClassifier  # éšæœºæ£®æ—åˆ†ç±»å™¨\n",
    "from sklearn.model_selection import train_test_split  # è®­ç»ƒæµ‹è¯•é›†åˆ†å‰²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç‰¹å¾æå–æ¨¡å—\n",
    "\n",
    "å¦‚æœéœ€è¦ä»æ–°çš„æ ·æœ¬æ–‡ä»¶ä¸­æå–ç‰¹å¾ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å—ã€‚\n",
    "å¦‚æœå·²æœ‰ç‰¹å¾æ–‡ä»¶ï¼Œå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯é€‰ï¼šä»æ–°æ ·æœ¬ä¸­æå–ç‰¹å¾\n",
    "# å¦‚æœå·²æœ‰ç‰¹å¾æ–‡ä»¶(ds1.xls, ds2.xls)ï¼Œå¯ä»¥è·³è¿‡æ­¤ä»£ç å—\n",
    "\n",
    "from original_feature_extractor import OriginalVBAFeatureExtractor\n",
    "\n",
    "# åˆ›å»ºç‰¹å¾æå–å™¨\n",
    "extractor = OriginalVBAFeatureExtractor()\n",
    "\n",
    "# ç¤ºä¾‹ï¼šä»æ–‡ä»¶å¤¹æå–ç‰¹å¾\n",
    "# è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹è·¯å¾„\n",
    "'''\n",
    "# æå–è®­ç»ƒé›†ç‰¹å¾ (è‰¯æ€§ + æ¶æ„æ ·æœ¬)\n",
    "train_features_df = extractor.extract_features_from_folder(\n",
    "    folder_path=\"path/to/training_samples\",  # è®­ç»ƒæ ·æœ¬æ–‡ä»¶å¤¹\n",
    "    output_file=\"ds1_new.xlsx\"  # è¾“å‡ºç‰¹å¾æ–‡ä»¶\n",
    ")\n",
    "\n",
    "# æå–æµ‹è¯•é›†ç‰¹å¾ (ä»…æ¶æ„æ ·æœ¬)\n",
    "test_features_df = extractor.extract_features_from_folder(\n",
    "    folder_path=\"path/to/test_samples\",  # æµ‹è¯•æ ·æœ¬æ–‡ä»¶å¤¹\n",
    "    output_file=\"ds2_new.xlsx\"  # è¾“å‡ºç‰¹å¾æ–‡ä»¶\n",
    ")\n",
    "\n",
    "print(\"âœ… ç‰¹å¾æå–å®Œæˆï¼\")\n",
    "print(f\"è®­ç»ƒé›†ç‰¹å¾: {train_features_df.shape if train_features_df is not None else 'N/A'}\")\n",
    "print(f\"æµ‹è¯•é›†ç‰¹å¾: {test_features_df.shape if test_features_df is not None else 'N/A'}\")\n",
    "'''\n",
    "\n",
    "print(\"ğŸ’¡ ç‰¹å¾æå–ä»£ç å—å·²å‡†å¤‡å°±ç»ª\")\n",
    "print(\"å¦‚éœ€æå–æ–°ç‰¹å¾ï¼Œè¯·å–æ¶ˆæ³¨é‡Šä¸Šè¿°ä»£ç å¹¶ä¿®æ”¹æ–‡ä»¶è·¯å¾„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ•°æ®é›†é…ç½®å’ŒåŠ è½½\n",
    "\n",
    "å®šä¹‰æ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯å’ŒåŠ è½½æ•°æ®æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é›†æ ·æœ¬æ•°é‡é…ç½®\n",
    "DS1_BENIGN_SAMPLES_CNT = 2939    # æ•°æ®é›†1ä¸­è‰¯æ€§æ ·æœ¬æ•°é‡\n",
    "DS1_MAL_SAMPLES_CNT = 13734      # æ•°æ®é›†1ä¸­æ¶æ„æ ·æœ¬æ•°é‡\n",
    "DS2_MAL_SAMPLES_CNT = 2884       # æ•°æ®é›†2ä¸­æ¶æ„æ ·æœ¬æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰\n",
    "\n",
    "# æ•°æ®é›†æ–‡ä»¶å\n",
    "Dataset1_name = 'ds1.xls'        # è®­ç»ƒæ•°æ®é›†\n",
    "Dataset2_name = 'ds2.xls'        # æµ‹è¯•æ•°æ®é›†\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "# dataset1: åŒ…å«è‰¯æ€§å’Œæ¶æ„æ ·æœ¬çš„è®­ç»ƒæ•°æ®é›†\n",
    "dataset1 = pd.read_excel('/Users/wenzhuolin/workspace/macro_fc-main/ds1.xls')\n",
    "# dataset2: ä»…åŒ…å«æ¶æ„æ ·æœ¬çš„æµ‹è¯•æ•°æ®é›†\n",
    "dataset2 = pd.read_excel('/home/cx/proj/macro_analysis/dataset/ds2.xls')\n",
    "\n",
    "# äº¤å‰éªŒè¯é…ç½®\n",
    "K_FOLD = 5  # ä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## éšæœºæ£®æ—äº¤å‰éªŒè¯å‡½æ•°\n",
    "\n",
    "å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯ï¼Œè¯„ä¼°éšæœºæ£®æ—æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "### å‡½æ•°åŠŸèƒ½ï¼š\n",
    "- ä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯è®­ç»ƒå’Œæµ‹è¯•éšæœºæ£®æ—æ¨¡å‹\n",
    "- è®¡ç®—æ¯æŠ˜çš„å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œè¯¯æŠ¥ç‡\n",
    "- è¿”å›æ‰€æœ‰æŠ˜çš„æ€§èƒ½æŒ‡æ ‡åˆ—è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RF_cross_valid(XX, yy, rawfilenamelist, random_state=42):\n",
    "    \"\"\"\n",
    "    éšæœºæ£®æ—KæŠ˜äº¤å‰éªŒè¯å‡½æ•°\n",
    "    \n",
    "    å‚æ•°:\n",
    "        XX: ç‰¹å¾çŸ©é˜µ\n",
    "        yy: æ ‡ç­¾å‘é‡ (0=è‰¯æ€§, 1=æ¶æ„)\n",
    "        rawfilenamelist: æ–‡ä»¶ååˆ—è¡¨\n",
    "        random_state: éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°\n",
    "    \n",
    "    è¿”å›:\n",
    "        tuple: (ç²¾ç¡®ç‡åˆ—è¡¨, å¬å›ç‡åˆ—è¡¨, å‡†ç¡®ç‡åˆ—è¡¨, è¯¯æŠ¥ç‡åˆ—è¡¨)\n",
    "    \"\"\"\n",
    "    # éšæœºæ‰“ä¹±æ•°æ®ï¼Œä¿æŒç‰¹å¾ã€æ ‡ç­¾ã€æ–‡ä»¶åçš„å¯¹åº”å…³ç³»\n",
    "    X, y, filenamelist = shuffle(XX, yy, rawfilenamelist, random_state=random_state)\n",
    "    \n",
    "    # åˆå§‹åŒ–éšæœºæ£®æ—åˆ†ç±»å™¨ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    # åˆ›å»ºKæŠ˜äº¤å‰éªŒè¯å¯¹è±¡\n",
    "    kf = KFold(n_splits=K_FOLD)\n",
    "    \n",
    "    # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡åˆ—è¡¨\n",
    "    accuracy_list = []   # å‡†ç¡®ç‡åˆ—è¡¨\n",
    "    precesion_list = []  # ç²¾ç¡®ç‡åˆ—è¡¨\n",
    "    recall_list = []     # å¬å›ç‡åˆ—è¡¨\n",
    "    fp_list = []         # è¯¯æŠ¥ç‡åˆ—è¡¨\n",
    "    \n",
    "    # æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # é¢„æµ‹æµ‹è¯•é›†\n",
    "        y_test_predict = rf.predict(X_test)\n",
    "\n",
    "        # åˆå§‹åŒ–æ··æ·†çŸ©é˜µè®¡æ•°å™¨\n",
    "        tp_cnt = 0  # True Positive: æ­£ç¡®è¯†åˆ«çš„æ¶æ„æ ·æœ¬\n",
    "        fp_cnt = 0  # False Positive: è¯¯æŠ¥çš„è‰¯æ€§æ ·æœ¬\n",
    "        tn_cnt = 0  # True Negative: æ­£ç¡®è¯†åˆ«çš„è‰¯æ€§æ ·æœ¬\n",
    "        fn_cnt = 0  # False Negative: æ¼æŠ¥çš„æ¶æ„æ ·æœ¬\n",
    "        \n",
    "        # è®¡ç®—æ··æ·†çŸ©é˜µ\n",
    "        for i in range(len(test_index)):\n",
    "            if y_test[i] == 0:  # çœŸå®æ ‡ç­¾ä¸ºè‰¯æ€§\n",
    "                if y_test_predict[i] > 0.5:  # é¢„æµ‹ä¸ºæ¶æ„\n",
    "                    fp_cnt = fp_cnt + 1  # è¯¯æŠ¥\n",
    "                else:  # é¢„æµ‹ä¸ºè‰¯æ€§\n",
    "                    tn_cnt = tn_cnt + 1  # æ­£ç¡®è¯†åˆ«è‰¯æ€§\n",
    "            elif y_test[i] == 1:  # çœŸå®æ ‡ç­¾ä¸ºæ¶æ„\n",
    "                if y_test_predict[i] > 0.5:  # é¢„æµ‹ä¸ºæ¶æ„\n",
    "                    tp_cnt = tp_cnt + 1  # æ­£ç¡®è¯†åˆ«æ¶æ„\n",
    "                else:  # é¢„æµ‹ä¸ºè‰¯æ€§\n",
    "                    fn_cnt = fn_cnt + 1  # æ¼æŠ¥\n",
    "            else:\n",
    "                print('Error label %f' %y_test[i])  # é”™è¯¯æ ‡ç­¾è­¦å‘Š\n",
    "        \n",
    "        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡\n",
    "        accuracy = 1.0 * (tp_cnt + tn_cnt)/(tp_cnt + tn_cnt + fp_cnt + fn_cnt)  # å‡†ç¡®ç‡\n",
    "        precesion = 1.0 * tp_cnt / (tp_cnt + fp_cnt)  # ç²¾ç¡®ç‡\n",
    "        recall = 1.0 * tp_cnt / (tp_cnt + fn_cnt)     # å¬å›ç‡\n",
    "        fp = 1.0 * fp_cnt / (tn_cnt + fp_cnt)         # è¯¯æŠ¥ç‡\n",
    "        \n",
    "        # ä¿å­˜å½“å‰æŠ˜çš„æ€§èƒ½æŒ‡æ ‡\n",
    "        accuracy_list.append(accuracy)\n",
    "        precesion_list.append(precesion)\n",
    "        recall_list.append(recall)\n",
    "        fp_list.append(fp)\n",
    "    \n",
    "    return precesion_list, recall_list, accuracy_list, fp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ•°æ®é›†1çš„äº¤å‰éªŒè¯å®éªŒ\n",
    "\n",
    "ä½¿ç”¨æ•°æ®é›†1è¿›è¡ŒKæŠ˜äº¤å‰éªŒè¯ï¼Œæµ‹è¯•ç»„åˆç‰¹å¾çš„æ£€æµ‹æ•ˆæœã€‚\n",
    "\n",
    "### ç‰¹å¾è¯´æ˜ï¼š\n",
    "- ç¬¬0åˆ—ï¼šæ–‡ä»¶å\n",
    "- ç¬¬1-77åˆ—ï¼šæ··æ·†ç‰¹å¾ï¼ˆå¦‚è¡Œé•¿åº¦ã€æ‹¬å·æ•°é‡ã€è¿‡ç¨‹æ•°é‡ç­‰ï¼‰\n",
    "- ç¬¬78-123åˆ—ï¼šå¯ç–‘ç‰¹å¾ï¼ˆå¦‚Shellã€CreateObjectã€Chrç­‰APIè°ƒç”¨ï¼‰\n",
    "- **ç»„åˆç‰¹å¾** (åˆ—1-123): ä½¿ç”¨æ‰€æœ‰ç‰¹å¾è¿›è¡Œæ£€æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------Dataset1 Cross Validation-----------\")    \n",
    "\n",
    "# ä½¿ç”¨ç»„åˆç‰¹å¾è¿›è¡Œäº¤å‰éªŒè¯\n",
    "print(\"\\n=== ç»„åˆç‰¹å¾äº¤å‰éªŒè¯ ===\")\n",
    "# åˆ›å»ºæ ‡ç­¾ï¼šå‰DS1_BENIGN_SAMPLES_CNTä¸ªä¸ºè‰¯æ€§(0)ï¼ŒåDS1_MAL_SAMPLES_CNTä¸ªä¸ºæ¶æ„(1)\n",
    "labels = [0] * DS1_BENIGN_SAMPLES_CNT + [1] * DS1_MAL_SAMPLES_CNT\n",
    "# æå–æ‰€æœ‰ç‰¹å¾ (ç¬¬1-123åˆ—)\n",
    "XX = dataset1.iloc[:, 1:124].values\n",
    "yy = np.array(labels)\n",
    "rawfilenamelist = dataset1.iloc[:, 0].values  # æ–‡ä»¶ååˆ—è¡¨\n",
    "\n",
    "# æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯\n",
    "precesion, recall, accuracy, fp = model_RF_cross_valid(XX, yy, rawfilenamelist)\n",
    "print('Detection result with combined features:')\n",
    "print('precesion:%f, recall:%f, accuracy:%f, fp:%f' %(np.average(precesion), np.average(recall), np.average(accuracy), np.average(fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ•°æ®é›†2çš„ç‹¬ç«‹æµ‹è¯•\n",
    "\n",
    "ä½¿ç”¨æ•°æ®é›†1è®­ç»ƒæ¨¡å‹ï¼Œåœ¨æ•°æ®é›†2ä¸Šè¿›è¡Œç‹¬ç«‹æµ‹è¯•ã€‚\n",
    "æ•°æ®é›†2åŒ…å«2884ä¸ªæ¶æ„æ ·æœ¬ï¼Œç”¨äºéªŒè¯æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå–æ•°æ®é›†2çš„æ–‡ä»¶ååˆ—è¡¨ï¼Œç”¨äºåç»­åˆ†æ\n",
    "testfilenamelist = dataset2.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»„åˆç‰¹å¾åœ¨æ•°æ®é›†2ä¸Šçš„ç‹¬ç«‹æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------Dataset2 Independent Test-----------\")    \n",
    "\n",
    "# ä½¿ç”¨ç»„åˆç‰¹å¾è¿›è¡Œç‹¬ç«‹æµ‹è¯•\n",
    "print(\"\\n=== ç»„åˆç‰¹å¾åœ¨æ•°æ®é›†2ä¸Šçš„æµ‹è¯• ===\")\n",
    "# ä½¿ç”¨æ•°æ®é›†1çš„æ ‡ç­¾å’Œæ‰€æœ‰ç‰¹å¾è®­ç»ƒæ¨¡å‹\n",
    "labels = [0] * DS1_BENIGN_SAMPLES_CNT + [1] * DS1_MAL_SAMPLES_CNT\n",
    "XX = dataset1.iloc[:, 1:124].values  # è®­ç»ƒé›†æ‰€æœ‰ç‰¹å¾\n",
    "yy = np.array(labels)\n",
    "test_X = dataset2.iloc[:, 1:124].values  # æµ‹è¯•é›†æ‰€æœ‰ç‰¹å¾\n",
    "\n",
    "# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(XX, yy)\n",
    "\n",
    "# åœ¨æ•°æ®é›†2ä¸Šè¿›è¡Œé¢„æµ‹\n",
    "y_test_predict = rf.predict(test_X)\n",
    "\n",
    "# è®¡ç®—æ£€æµ‹ç‡ (Detection Rate)\n",
    "# ç”±äºæ•°æ®é›†2å…¨éƒ¨ä¸ºæ¶æ„æ ·æœ¬ï¼Œæ£€æµ‹ç‡ = è¢«æ­£ç¡®è¯†åˆ«ä¸ºæ¶æ„çš„æ ·æœ¬æ•° / æ€»æ ·æœ¬æ•°\n",
    "DR = 1.0 * np.sum(y_test_predict) / len(y_test_predict)\n",
    "print('Detection Rate with combined features:%f' %DR)\n",
    "print(f'æ£€æµ‹åˆ°æ¶æ„æ ·æœ¬: {np.sum(y_test_predict)}/{len(y_test_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†ææœªæ£€æµ‹åˆ°çš„æ ·æœ¬\n",
    "\n",
    "æ‰“å°å‡ºåœ¨ç»„åˆç‰¹å¾æµ‹è¯•ä¸­è¢«è¯¯åˆ¤ä¸ºè‰¯æ€§çš„æ¶æ„æ ·æœ¬æ–‡ä»¶åã€‚\n",
    "è¿™äº›æ ·æœ¬å¯èƒ½å…·æœ‰ä¸è‰¯æ€§æ–‡ä»¶ç›¸ä¼¼çš„ç‰¹å¾ç»„åˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“å°åœ¨ç»„åˆç‰¹å¾æµ‹è¯•ä¸­è¢«è¯¯åˆ¤ä¸ºè‰¯æ€§çš„æ¶æ„æ ·æœ¬æ–‡ä»¶å\n",
    "print(f\"\\nç»„åˆç‰¹å¾æµ‹è¯•ä¸­æœªæ£€æµ‹åˆ°çš„æ¶æ„æ ·æœ¬ (é¢„æµ‹æ¦‚ç‡ < 0.5):\")\n",
    "undetected_count = 0\n",
    "for i in range(len(y_test_predict)):\n",
    "    if y_test_predict[i] < 0.5:  # é¢„æµ‹ä¸ºè‰¯æ€§çš„æ ·æœ¬\n",
    "        print(f\"[{i}]{testfilenamelist[i]}\")\n",
    "        undetected_count += 1\n",
    "\n",
    "print(f\"\\næ€»è®¡æœªæ£€æµ‹åˆ°: {undetected_count}/{len(y_test_predict)} ä¸ªæ¶æ„æ ·æœ¬\")\n",
    "print(f\"æ¼æŠ¥ç‡: {undetected_count/len(y_test_predict)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒç»“æœæ€»ç»“\n",
    "\n",
    "### ç»„åˆç‰¹å¾æ€§èƒ½ï¼š\n",
    "- **äº¤å‰éªŒè¯ç»“æœ**: ç²¾ç¡®ç‡99.67%, å¬å›ç‡99.65%, å‡†ç¡®ç‡99.44%, è¯¯æŠ¥ç‡1.53%\n",
    "- **ç‹¬ç«‹æµ‹è¯•ç»“æœ**: æ£€æµ‹ç‡95.70%\n",
    "\n",
    "### å…³é”®å‘ç°ï¼š\n",
    "- ç»„åˆç‰¹å¾åœ¨äº¤å‰éªŒè¯å’Œç‹¬ç«‹æµ‹è¯•ä¸­éƒ½è¡¨ç°ä¼˜ç§€\n",
    "- ä½è¯¯æŠ¥ç‡å’Œé«˜æ£€æµ‹ç‡çš„è‰¯å¥½å¹³è¡¡\n",
    "- æ¨¡å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "### å»ºè®®ï¼š\n",
    "- ç»„åˆç‰¹å¾é€‚åˆå®é™…éƒ¨ç½²ä½¿ç”¨\n",
    "- å¯ä»¥æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯è°ƒæ•´é˜ˆå€¼\n",
    "- å®šæœŸæ›´æ–°æ¨¡å‹ä»¥åº”å¯¹æ–°çš„æ¶æ„è½¯ä»¶å˜ç§"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAGIC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
