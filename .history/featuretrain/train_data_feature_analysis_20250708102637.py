#!/usr/bin/env python3
"""
è®­ç»ƒæ•°æ®ç‰¹å¾åˆ†æè„šæœ¬
å¯¹train.csvå’Œdataæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®è¿›è¡Œå…¨é¢çš„ç‰¹å¾åˆ†æ
åŒ…æ‹¬ï¼šKSæ£€éªŒã€KDEæ›²çº¿å›¾ã€ä¸­ä½æ•°/å‡å€¼å·®åˆ†æ

åˆ†æç»„åˆï¼š
1. train.csvé»‘æ ·æœ¬ vs bad250623_features.csv
2. train.csvç™½æ ·æœ¬ vs good250623_features.csv
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import ks_2samp
import warnings
from pathlib import Path
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

warnings.filterwarnings('ignore')

class TrainDataFeatureAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–ç‰¹å¾åˆ†æå™¨"""
        self.output_dir = Path('featuretrain')
        self.output_dir.mkdir(exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.train_data = None
        self.train_black = None  # train.csvä¸­çš„æ¶æ„æ ·æœ¬
        self.train_white = None  # train.csvä¸­çš„è‰¯æ€§æ ·æœ¬
        self.bad250623_data = None
        self.good250623_data = None
        
        # åˆ†æç»“æœå­˜å‚¨
        self.black_analysis_results = {}
        self.white_analysis_results = {}
        
    def load_data(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®"""
        print("ğŸ“Š åŠ è½½æ•°æ®...")
        
        try:
            # åŠ è½½train.csv
            print("  ğŸ“– åŠ è½½train.csv...")
            self.train_data = pd.read_csv('train.csv')
            print(f"    âœ… train.csv: {len(self.train_data)} è¡Œ Ã— {len(self.train_data.columns)} åˆ—")
            
            # æ ¹æ®è®­ç»ƒè„šæœ¬çš„é…ç½®åˆ†å‰²é»‘ç™½æ ·æœ¬
            # å‰2939ä¸ªæ˜¯è‰¯æ€§æ ·æœ¬ï¼Œåé¢æ˜¯æ¶æ„æ ·æœ¬
            self.train_white = self.train_data.iloc[:2939].copy()
            self.train_black = self.train_data.iloc[2939:].copy()
            
            print(f"    ğŸ“‹ trainç™½æ ·æœ¬: {len(self.train_white)} ä¸ª")
            print(f"    ğŸ“‹ trainé»‘æ ·æœ¬: {len(self.train_black)} ä¸ª")
            
            # åŠ è½½dataæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®
            print("  ğŸ“– åŠ è½½dataæ–‡ä»¶å¤¹æ•°æ®...")
            self.bad250623_data = pd.read_csv('data/bad250623_features.csv')
            self.good250623_data = pd.read_csv('data/good250623_features.csv')
            
            print(f"    âœ… bad250623: {len(self.bad250623_data)} è¡Œ Ã— {len(self.bad250623_data.columns)} åˆ—")
            print(f"    âœ… good250623: {len(self.good250623_data)} è¡Œ Ã— {len(self.good250623_data.columns)} åˆ—")
            
            # è·å–ç‰¹å¾åˆ—ï¼ˆæ’é™¤æ–‡ä»¶ååˆ—ï¼‰
            self.feature_columns = self.train_data.columns[1:].tolist()
            print(f"    ğŸ“‹ ç‰¹å¾ç»´åº¦: {len(self.feature_columns)}")
            
            return True
            
        except Exception as e:
            print(f"    âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def perform_ks_analysis(self, data1, data2, data1_name, data2_name, analysis_type):
        """æ‰§è¡ŒKSæ£€éªŒåˆ†æ"""
        print(f"\nğŸ” æ‰§è¡ŒKSæ£€éªŒ: {data1_name} vs {data2_name}")
        
        results = []
        
        for feature in self.feature_columns:
            try:
                # æå–ç‰¹å¾æ•°æ®
                values1 = data1[feature].dropna()
                values2 = data2[feature].dropna()
                
                if len(values1) == 0 or len(values2) == 0:
                    continue
                
                # KSæ£€éªŒ
                ks_stat, p_value = ks_2samp(values1, values2)
                
                # è®¡ç®—ç»Ÿè®¡é‡
                mean1, mean2 = values1.mean(), values2.mean()
                median1, median2 = values1.median(), values2.median()
                std1, std2 = values1.std(), values2.std()
                
                # è®¡ç®—å·®å¼‚
                mean_diff = abs(mean1 - mean2)
                median_diff = abs(median1 - median2)
                
                # æ•ˆåº”å¤§å° (Cohen's d)
                pooled_std = np.sqrt(((len(values1) - 1) * std1**2 + (len(values2) - 1) * std2**2) / 
                                   (len(values1) + len(values2) - 2))
                cohens_d = abs(mean1 - mean2) / pooled_std if pooled_std > 0 else 0
                
                results.append({
                    'feature': feature,
                    'ks_statistic': ks_stat,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    f'{data1_name}_mean': mean1,
                    f'{data2_name}_mean': mean2,
                    f'{data1_name}_median': median1,
                    f'{data2_name}_median': median2,
                    f'{data1_name}_std': std1,
                    f'{data2_name}_std': std2,
                    'mean_diff': mean_diff,
                    'median_diff': median_diff,
                    'cohens_d': cohens_d,
                    f'{data1_name}_count': len(values1),
                    f'{data2_name}_count': len(values2)
                })
                
            except Exception as e:
                print(f"    âš ï¸  ç‰¹å¾ {feature} åˆ†æå¤±è´¥: {e}")
                continue
        
        # è½¬æ¢ä¸ºDataFrame
        results_df = pd.DataFrame(results)
        
        if len(results_df) > 0:
            # æŒ‰KSç»Ÿè®¡é‡æ’åº
            results_df = results_df.sort_values('ks_statistic', ascending=False)
            
            # ä¿å­˜ç»“æœ
            output_file = self.output_dir / f'ks_analysis_{analysis_type}.csv'
            results_df.to_csv(output_file, index=False, encoding='utf-8')
            print(f"    âœ… KSåˆ†æç»“æœå·²ä¿å­˜: {output_file}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            significant_count = results_df['significant'].sum()
            print(f"    ğŸ“Š æ˜¾è‘—å·®å¼‚ç‰¹å¾: {significant_count}/{len(results_df)}")
            print(f"    ğŸ“Š å¹³å‡KSç»Ÿè®¡é‡: {results_df['ks_statistic'].mean():.4f}")
            
            return results_df
        else:
            print(f"    âŒ æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ")
            return None
    
    def create_kde_plots(self, data1, data2, data1_name, data2_name, analysis_type, top_n=12):
        """åˆ›å»ºKDEæ›²çº¿å›¾"""
        print(f"\nğŸ“ˆ ç”ŸæˆKDEæ›²çº¿å›¾: {data1_name} vs {data2_name}")
        
        # è·å–KSç»Ÿè®¡é‡æœ€å¤§çš„ç‰¹å¾
        if analysis_type == 'black_comparison':
            results_df = self.black_analysis_results
        else:
            results_df = self.white_analysis_results
            
        if results_df is None or len(results_df) == 0:
            print("    âŒ æ²¡æœ‰åˆ†æç»“æœï¼Œæ— æ³•ç”ŸæˆKDEå›¾")
            return
        
        top_features = results_df.head(top_n)['feature'].tolist()
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        fig.suptitle(f'KDEåˆ†å¸ƒå¯¹æ¯”: {data1_name} vs {data2_name}', fontsize=16, fontweight='bold')
        
        for i, feature in enumerate(top_features):
            row, col = i // 4, i % 4
            ax = axes[row, col]
            
            try:
                # æå–æ•°æ®
                values1 = data1[feature].dropna()
                values2 = data2[feature].dropna()
                
                if len(values1) == 0 or len(values2) == 0:
                    ax.text(0.5, 0.5, 'No Data', ha='center', va='center', transform=ax.transAxes)
                    ax.set_title(feature)
                    continue
                
                # ç»˜åˆ¶KDEæ›²çº¿
                if len(values1) > 1:
                    sns.kdeplot(data=values1, ax=ax, label=data1_name, alpha=0.7, color='red')
                if len(values2) > 1:
                    sns.kdeplot(data=values2, ax=ax, label=data2_name, alpha=0.7, color='blue')
                
                # æ·»åŠ å‡å€¼çº¿
                ax.axvline(values1.mean(), color='red', linestyle='--', alpha=0.8, linewidth=1)
                ax.axvline(values2.mean(), color='blue', linestyle='--', alpha=0.8, linewidth=1)
                
                # è·å–KSç»Ÿè®¡é‡
                ks_stat = results_df[results_df['feature'] == feature]['ks_statistic'].iloc[0]
                p_val = results_df[results_df['feature'] == feature]['p_value'].iloc[0]
                
                ax.set_title(f'{feature}\nKS={ks_stat:.3f}, p={p_val:.3e}', fontsize=10)
                ax.legend(fontsize=8)
                ax.grid(True, alpha=0.3)
                
            except Exception as e:
                ax.text(0.5, 0.5, f'Error: {str(e)[:20]}', ha='center', va='center', transform=ax.transAxes)
                ax.set_title(feature)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_file = self.output_dir / f'kde_plots_{analysis_type}.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"    âœ… KDEå›¾å·²ä¿å­˜: {output_file}")

    def create_statistical_summary(self, analysis_type):
        """åˆ›å»ºç»Ÿè®¡æ‘˜è¦æŠ¥å‘Š"""
        print(f"\nğŸ“‹ ç”Ÿæˆç»Ÿè®¡æ‘˜è¦: {analysis_type}")

        if analysis_type == 'black_comparison':
            results_df = self.black_analysis_results
            data1_name = 'train_black'
            data2_name = 'bad250623'
        else:
            results_df = self.white_analysis_results
            data1_name = 'train_white'
            data2_name = 'good250623'

        if results_df is None or len(results_df) == 0:
            print("    âŒ æ²¡æœ‰åˆ†æç»“æœ")
            return

        # åˆ›å»ºæ‘˜è¦ç»Ÿè®¡
        summary = {
            'æ€»ç‰¹å¾æ•°': len(results_df),
            'æ˜¾è‘—å·®å¼‚ç‰¹å¾æ•°': results_df['significant'].sum(),
            'æ˜¾è‘—å·®å¼‚æ¯”ä¾‹': f"{results_df['significant'].mean():.2%}",
            'å¹³å‡KSç»Ÿè®¡é‡': f"{results_df['ks_statistic'].mean():.4f}",
            'æœ€å¤§KSç»Ÿè®¡é‡': f"{results_df['ks_statistic'].max():.4f}",
            'å¹³å‡å‡å€¼å·®': f"{results_df['mean_diff'].mean():.4f}",
            'å¹³å‡ä¸­ä½æ•°å·®': f"{results_df['median_diff'].mean():.4f}",
            'å¹³å‡æ•ˆåº”å¤§å°': f"{results_df['cohens_d'].mean():.4f}"
        }

        # ä¿å­˜æ‘˜è¦
        summary_file = self.output_dir / f'statistical_summary_{analysis_type}.txt'
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"ç‰¹å¾åˆ†æç»Ÿè®¡æ‘˜è¦: {data1_name} vs {data2_name}\n")
            f.write("=" * 60 + "\n\n")

            for key, value in summary.items():
                f.write(f"{key}: {value}\n")

            f.write("\n" + "=" * 60 + "\n")
            f.write("å‰10ä¸ªå·®å¼‚æœ€å¤§çš„ç‰¹å¾:\n")
            f.write("-" * 40 + "\n")

            top_features = results_df.head(10)
            for idx, row in top_features.iterrows():
                f.write(f"{row['feature']}: KS={row['ks_statistic']:.4f}, "
                       f"p={row['p_value']:.2e}, Cohen's d={row['cohens_d']:.4f}\n")

        print(f"    âœ… ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜: {summary_file}")

        # æ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯
        print(f"    ğŸ“Š å…³é”®ç»Ÿè®¡:")
        print(f"       - æ˜¾è‘—å·®å¼‚ç‰¹å¾: {summary['æ˜¾è‘—å·®å¼‚ç‰¹å¾æ•°']}/{summary['æ€»ç‰¹å¾æ•°']} ({summary['æ˜¾è‘—å·®å¼‚æ¯”ä¾‹']})")
        print(f"       - å¹³å‡KSç»Ÿè®¡é‡: {summary['å¹³å‡KSç»Ÿè®¡é‡']}")
        print(f"       - æœ€å¤§KSç»Ÿè®¡é‡: {summary['æœ€å¤§KSç»Ÿè®¡é‡']}")

    def create_comparison_heatmap(self, analysis_type, top_n=20):
        """åˆ›å»ºç‰¹å¾å¯¹æ¯”çƒ­åŠ›å›¾"""
        print(f"\nğŸ”¥ ç”Ÿæˆå¯¹æ¯”çƒ­åŠ›å›¾: {analysis_type}")

        if analysis_type == 'black_comparison':
            results_df = self.black_analysis_results
            data1_name = 'train_black'
            data2_name = 'bad250623'
        else:
            results_df = self.white_analysis_results
            data1_name = 'train_white'
            data2_name = 'good250623'

        if results_df is None or len(results_df) == 0:
            print("    âŒ æ²¡æœ‰åˆ†æç»“æœ")
            return

        # é€‰æ‹©å‰Nä¸ªå·®å¼‚æœ€å¤§çš„ç‰¹å¾
        top_features = results_df.head(top_n)

        # å‡†å¤‡çƒ­åŠ›å›¾æ•°æ®
        heatmap_data = []
        feature_names = []

        for _, row in top_features.iterrows():
            feature_names.append(row['feature'])
            heatmap_data.append([
                row['ks_statistic'],
                row['cohens_d'],
                row['mean_diff'],
                row['median_diff'],
                1 if row['significant'] else 0
            ])

        heatmap_df = pd.DataFrame(
            heatmap_data,
            index=feature_names,
            columns=['KSç»Ÿè®¡é‡', 'Cohen\'s d', 'å‡å€¼å·®', 'ä¸­ä½æ•°å·®', 'æ˜¾è‘—æ€§']
        )

        # æ ‡å‡†åŒ–æ•°æ®ï¼ˆé™¤äº†æ˜¾è‘—æ€§ï¼‰
        for col in heatmap_df.columns[:-1]:
            heatmap_df[col] = (heatmap_df[col] - heatmap_df[col].min()) / (heatmap_df[col].max() - heatmap_df[col].min())

        # åˆ›å»ºçƒ­åŠ›å›¾
        plt.figure(figsize=(10, max(8, len(feature_names) * 0.4)))
        sns.heatmap(heatmap_df, annot=True, fmt='.3f', cmap='YlOrRd',
                   cbar_kws={'label': 'æ ‡å‡†åŒ–å€¼'})
        plt.title(f'ç‰¹å¾å·®å¼‚çƒ­åŠ›å›¾: {data1_name} vs {data2_name}', fontsize=14, fontweight='bold')
        plt.xlabel('ç»Ÿè®¡æŒ‡æ ‡')
        plt.ylabel('ç‰¹å¾åç§°')
        plt.tight_layout()

        # ä¿å­˜å›¾ç‰‡
        output_file = self.output_dir / f'comparison_heatmap_{analysis_type}.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"    âœ… çƒ­åŠ›å›¾å·²ä¿å­˜: {output_file}")

    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print("ğŸ¯ è®­ç»ƒæ•°æ®ç‰¹å¾åˆ†æ")
        print("=" * 60)

        # 1. åŠ è½½æ•°æ®
        if not self.load_data():
            return False

        # 2. é»‘æ ·æœ¬å¯¹æ¯”åˆ†æ (trainé»‘æ ·æœ¬ vs bad250623)
        print(f"\nğŸ”´ é»‘æ ·æœ¬å¯¹æ¯”åˆ†æ")
        print("-" * 40)
        self.black_analysis_results = self.perform_ks_analysis(
            self.train_black, self.bad250623_data,
            'train_black', 'bad250623', 'black_comparison'
        )

        if self.black_analysis_results is not None:
            self.create_kde_plots(
                self.train_black, self.bad250623_data,
                'train_black', 'bad250623', 'black_comparison'
            )
            self.create_statistical_summary('black_comparison')
            self.create_comparison_heatmap('black_comparison')

        # 3. ç™½æ ·æœ¬å¯¹æ¯”åˆ†æ (trainç™½æ ·æœ¬ vs good250623)
        print(f"\nâšª ç™½æ ·æœ¬å¯¹æ¯”åˆ†æ")
        print("-" * 40)
        self.white_analysis_results = self.perform_ks_analysis(
            self.train_white, self.good250623_data,
            'train_white', 'good250623', 'white_comparison'
        )

        if self.white_analysis_results is not None:
            self.create_kde_plots(
                self.train_white, self.good250623_data,
                'train_white', 'good250623', 'white_comparison'
            )
            self.create_statistical_summary('white_comparison')
            self.create_comparison_heatmap('white_comparison')

        # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()

        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° featuretrain/ æ–‡ä»¶å¤¹")
        return True

    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print(f"\nğŸ“„ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")

        report_file = self.output_dir / 'comprehensive_analysis_report.md'

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# è®­ç»ƒæ•°æ®ç‰¹å¾åˆ†æç»¼åˆæŠ¥å‘Š\n\n")
            f.write("## åˆ†ææ¦‚è¿°\n\n")
            f.write("æœ¬æŠ¥å‘Šå¯¹train.csvè®­ç»ƒæ•°æ®ä¸dataæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®è¿›è¡Œäº†å…¨é¢çš„ç‰¹å¾å¯¹æ¯”åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n\n")
            f.write("1. **é»‘æ ·æœ¬å¯¹æ¯”**: train.csvä¸­çš„æ¶æ„æ ·æœ¬ vs bad250623_features.csv\n")
            f.write("2. **ç™½æ ·æœ¬å¯¹æ¯”**: train.csvä¸­çš„è‰¯æ€§æ ·æœ¬ vs good250623_features.csv\n\n")

            f.write("## åˆ†ææ–¹æ³•\n\n")
            f.write("- **KSæ£€éªŒ**: æ£€æµ‹ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„å·®å¼‚\n")
            f.write("- **KDEæ›²çº¿å›¾**: å¯è§†åŒ–ç‰¹å¾åˆ†å¸ƒ\n")
            f.write("- **ç»Ÿè®¡å·®å¼‚**: å‡å€¼å·®ã€ä¸­ä½æ•°å·®ã€æ•ˆåº”å¤§å°\n")
            f.write("- **çƒ­åŠ›å›¾**: å¤šç»´åº¦ç‰¹å¾å¯¹æ¯”\n\n")

            f.write("## æ•°æ®æ¦‚å†µ\n\n")
            f.write(f"- **train.csvæ€»æ ·æœ¬**: {len(self.train_data)}\n")
            f.write(f"- **trainç™½æ ·æœ¬**: {len(self.train_white)}\n")
            f.write(f"- **trainé»‘æ ·æœ¬**: {len(self.train_black)}\n")
            f.write(f"- **good250623æ ·æœ¬**: {len(self.good250623_data)}\n")
            f.write(f"- **bad250623æ ·æœ¬**: {len(self.bad250623_data)}\n")
            f.write(f"- **ç‰¹å¾ç»´åº¦**: {len(self.feature_columns)}\n\n")

            # é»‘æ ·æœ¬åˆ†æç»“æœ
            if self.black_analysis_results is not None:
                f.write("## é»‘æ ·æœ¬å¯¹æ¯”åˆ†æç»“æœ\n\n")
                significant_black = self.black_analysis_results['significant'].sum()
                total_black = len(self.black_analysis_results)
                f.write(f"- **æ˜¾è‘—å·®å¼‚ç‰¹å¾**: {significant_black}/{total_black} ({significant_black/total_black:.1%})\n")
                f.write(f"- **å¹³å‡KSç»Ÿè®¡é‡**: {self.black_analysis_results['ks_statistic'].mean():.4f}\n")
                f.write(f"- **æœ€å¤§KSç»Ÿè®¡é‡**: {self.black_analysis_results['ks_statistic'].max():.4f}\n\n")

            # ç™½æ ·æœ¬åˆ†æç»“æœ
            if self.white_analysis_results is not None:
                f.write("## ç™½æ ·æœ¬å¯¹æ¯”åˆ†æç»“æœ\n\n")
                significant_white = self.white_analysis_results['significant'].sum()
                total_white = len(self.white_analysis_results)
                f.write(f"- **æ˜¾è‘—å·®å¼‚ç‰¹å¾**: {significant_white}/{total_white} ({significant_white/total_white:.1%})\n")
                f.write(f"- **å¹³å‡KSç»Ÿè®¡é‡**: {self.white_analysis_results['ks_statistic'].mean():.4f}\n")
                f.write(f"- **æœ€å¤§KSç»Ÿè®¡é‡**: {self.white_analysis_results['ks_statistic'].max():.4f}\n\n")

            f.write("## ç”Ÿæˆçš„æ–‡ä»¶\n\n")
            f.write("### æ•°æ®æ–‡ä»¶\n")
            f.write("- `ks_analysis_black_comparison.csv`: é»‘æ ·æœ¬KSæ£€éªŒç»“æœ\n")
            f.write("- `ks_analysis_white_comparison.csv`: ç™½æ ·æœ¬KSæ£€éªŒç»“æœ\n")
            f.write("- `statistical_summary_black_comparison.txt`: é»‘æ ·æœ¬ç»Ÿè®¡æ‘˜è¦\n")
            f.write("- `statistical_summary_white_comparison.txt`: ç™½æ ·æœ¬ç»Ÿè®¡æ‘˜è¦\n\n")

            f.write("### å¯è§†åŒ–æ–‡ä»¶\n")
            f.write("- `kde_plots_black_comparison.png`: é»‘æ ·æœ¬KDEåˆ†å¸ƒå›¾\n")
            f.write("- `kde_plots_white_comparison.png`: ç™½æ ·æœ¬KDEåˆ†å¸ƒå›¾\n")
            f.write("- `comparison_heatmap_black_comparison.png`: é»‘æ ·æœ¬å¯¹æ¯”çƒ­åŠ›å›¾\n")
            f.write("- `comparison_heatmap_white_comparison.png`: ç™½æ ·æœ¬å¯¹æ¯”çƒ­åŠ›å›¾\n\n")

            f.write("## ç»“è®º\n\n")
            f.write("è¯¦ç»†çš„åˆ†æç»“æœè¯·æŸ¥çœ‹å„ä¸ªå…·ä½“çš„æ•°æ®æ–‡ä»¶å’Œå¯è§†åŒ–å›¾è¡¨ã€‚\n")

        print(f"    âœ… ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = TrainDataFeatureAnalyzer()
    success = analyzer.run_analysis()

    if success:
        print("\nâœ… ç‰¹å¾åˆ†æå®Œæˆï¼")
        print("ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° featuretrain/ æ–‡ä»¶å¤¹")
    else:
        print("\nâŒ ç‰¹å¾åˆ†æå¤±è´¥ï¼")

if __name__ == "__main__":
    main()
