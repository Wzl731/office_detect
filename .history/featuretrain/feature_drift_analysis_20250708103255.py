#!/usr/bin/env python3
"""
ç‰¹å¾åç§»æ·±åº¦åˆ†æè„šæœ¬
ä¸“é—¨åˆ†ætrain.csvå’Œdataæ–‡ä»¶å¤¹æ•°æ®ä¹‹é—´çš„ç‰¹å¾åç§»é—®é¢˜
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class FeatureDriftAnalyzer:
    def __init__(self):
        self.output_dir = Path('featuretrain')
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("ğŸ“Š åŠ è½½æ•°æ®è¿›è¡Œåç§»åˆ†æ...")
        
        # åŠ è½½æ•°æ®
        self.train_data = pd.read_csv('train.csv')
        self.train_white = self.train_data.iloc[:2939].copy()
        self.train_black = self.train_data.iloc[2939:].copy()
        self.good250623 = pd.read_csv('data/good250623_features.csv')
        self.bad250623 = pd.read_csv('data/bad250623_features.csv')
        
        self.feature_columns = self.train_data.columns[1:].tolist()
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
        print(f"   - trainç™½æ ·æœ¬: {len(self.train_white)}")
        print(f"   - good250623: {len(self.good250623)}")
        print(f"   - trainé»‘æ ·æœ¬: {len(self.train_black)}")
        print(f"   - bad250623: {len(self.bad250623)}")
    
    def analyze_drift_severity(self):
        """åˆ†æåç§»ä¸¥é‡ç¨‹åº¦"""
        print("\nğŸ” åˆ†æç‰¹å¾åç§»ä¸¥é‡ç¨‹åº¦...")
        
        # è¯»å–ä¹‹å‰çš„KSåˆ†æç»“æœ
        white_ks = pd.read_csv('featuretrain/ks_analysis_white_comparison.csv')
        black_ks = pd.read_csv('featuretrain/ks_analysis_black_comparison.csv')
        
        # åç§»ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        def classify_drift(ks_stat):
            if ks_stat < 0.1:
                return "è½»å¾®åç§»"
            elif ks_stat < 0.2:
                return "ä¸­ç­‰åç§»"
            elif ks_stat < 0.4:
                return "ä¸¥é‡åç§»"
            else:
                return "æä¸¥é‡åç§»"
        
        white_ks['drift_level'] = white_ks['ks_statistic'].apply(classify_drift)
        black_ks['drift_level'] = black_ks['ks_statistic'].apply(classify_drift)
        
        # ç»Ÿè®¡åç§»ç¨‹åº¦
        print("\nğŸ“Š ç™½æ ·æœ¬åç§»ç¨‹åº¦ç»Ÿè®¡:")
        white_drift_stats = white_ks['drift_level'].value_counts()
        for level, count in white_drift_stats.items():
            print(f"   {level}: {count} ä¸ªç‰¹å¾ ({count/len(white_ks)*100:.1f}%)")
        
        print("\nğŸ“Š é»‘æ ·æœ¬åç§»ç¨‹åº¦ç»Ÿè®¡:")
        black_drift_stats = black_ks['drift_level'].value_counts()
        for level, count in black_drift_stats.items():
            print(f"   {level}: {count} ä¸ªç‰¹å¾ ({count/len(black_ks)*100:.1f}%)")
        
        # ä¿å­˜åç§»åˆ†æç»“æœ
        drift_summary = {
            'white_samples': {
                'total_features': len(white_ks),
                'significant_drift': white_ks['significant'].sum(),
                'severe_drift': len(white_ks[white_ks['ks_statistic'] >= 0.2]),
                'extreme_drift': len(white_ks[white_ks['ks_statistic'] >= 0.4]),
                'avg_ks': white_ks['ks_statistic'].mean(),
                'max_ks': white_ks['ks_statistic'].max()
            },
            'black_samples': {
                'total_features': len(black_ks),
                'significant_drift': black_ks['significant'].sum(),
                'severe_drift': len(black_ks[black_ks['ks_statistic'] >= 0.2]),
                'extreme_drift': len(black_ks[black_ks['ks_statistic'] >= 0.4]),
                'avg_ks': black_ks['ks_statistic'].mean(),
                'max_ks': black_ks['ks_statistic'].max()
            }
        }
        
        return drift_summary, white_ks, black_ks
    
    def create_drift_visualization(self, white_ks, black_ks):
        """åˆ›å»ºåç§»å¯è§†åŒ–"""
        print("\nğŸ“ˆ ç”Ÿæˆåç§»å¯è§†åŒ–å›¾è¡¨...")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. KSç»Ÿè®¡é‡åˆ†å¸ƒå¯¹æ¯”
        axes[0,0].hist(white_ks['ks_statistic'], bins=30, alpha=0.7, label='ç™½æ ·æœ¬åç§»', color='blue')
        axes[0,0].hist(black_ks['ks_statistic'], bins=30, alpha=0.7, label='é»‘æ ·æœ¬åç§»', color='red')
        axes[0,0].set_xlabel('KSç»Ÿè®¡é‡')
        axes[0,0].set_ylabel('ç‰¹å¾æ•°é‡')
        axes[0,0].set_title('ç‰¹å¾åç§»åˆ†å¸ƒå¯¹æ¯”')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. åç§»ä¸¥é‡ç¨‹åº¦å¯¹æ¯”
        white_levels = white_ks['drift_level'].value_counts()
        black_levels = black_ks['drift_level'].value_counts()
        
        levels = ['è½»å¾®åç§»', 'ä¸­ç­‰åç§»', 'ä¸¥é‡åç§»', 'æä¸¥é‡åç§»']
        white_counts = [white_levels.get(level, 0) for level in levels]
        black_counts = [black_levels.get(level, 0) for level in levels]
        
        x = np.arange(len(levels))
        width = 0.35
        
        axes[0,1].bar(x - width/2, white_counts, width, label='ç™½æ ·æœ¬', color='blue', alpha=0.7)
        axes[0,1].bar(x + width/2, black_counts, width, label='é»‘æ ·æœ¬', color='red', alpha=0.7)
        axes[0,1].set_xlabel('åç§»ç¨‹åº¦')
        axes[0,1].set_ylabel('ç‰¹å¾æ•°é‡')
        axes[0,1].set_title('åç§»ä¸¥é‡ç¨‹åº¦å¯¹æ¯”')
        axes[0,1].set_xticks(x)
        axes[0,1].set_xticklabels(levels, rotation=45)
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. å‰20ä¸ªåç§»æœ€ä¸¥é‡çš„ç™½æ ·æœ¬ç‰¹å¾
        top_white_drift = white_ks.head(20)
        axes[1,0].barh(range(len(top_white_drift)), top_white_drift['ks_statistic'], color='blue', alpha=0.7)
        axes[1,0].set_yticks(range(len(top_white_drift)))
        axes[1,0].set_yticklabels(top_white_drift['feature'], fontsize=8)
        axes[1,0].set_xlabel('KSç»Ÿè®¡é‡')
        axes[1,0].set_title('ç™½æ ·æœ¬åç§»æœ€ä¸¥é‡çš„20ä¸ªç‰¹å¾')
        axes[1,0].grid(True, alpha=0.3)
        
        # 4. æ•ˆåº”å¤§å°å¯¹æ¯”
        axes[1,1].scatter(white_ks['ks_statistic'], white_ks['cohens_d'], alpha=0.6, label='ç™½æ ·æœ¬', color='blue')
        axes[1,1].scatter(black_ks['ks_statistic'], black_ks['cohens_d'], alpha=0.6, label='é»‘æ ·æœ¬', color='red')
        axes[1,1].set_xlabel('KSç»Ÿè®¡é‡')
        axes[1,1].set_ylabel('Cohen\'s d (æ•ˆåº”å¤§å°)')
        axes[1,1].set_title('åç§»ç¨‹åº¦ vs æ•ˆåº”å¤§å°')
        axes[1,1].legend()
        axes[1,1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_file = self.output_dir / 'feature_drift_analysis.png'
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… åç§»åˆ†æå›¾å·²ä¿å­˜: {output_file}")
    
    def generate_drift_report(self, drift_summary):
        """ç”Ÿæˆåç§»åˆ†ææŠ¥å‘Š"""
        print("\nğŸ“„ ç”Ÿæˆåç§»åˆ†ææŠ¥å‘Š...")
        
        report_file = self.output_dir / 'feature_drift_report.md'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ç‰¹å¾åç§»åˆ†ææŠ¥å‘Š\n\n")
            
            f.write("## ğŸš¨ åç§»æ£€æµ‹ç»“æœ\n\n")
            f.write("### ç™½æ ·æœ¬åç§»æƒ…å†µ (trainç™½æ ·æœ¬ vs good250623)\n")
            white = drift_summary['white_samples']
            f.write(f"- **æ€»ç‰¹å¾æ•°**: {white['total_features']}\n")
            f.write(f"- **æ˜¾è‘—åç§»ç‰¹å¾**: {white['significant_drift']} ({white['significant_drift']/white['total_features']*100:.1f}%)\n")
            f.write(f"- **ä¸¥é‡åç§»ç‰¹å¾** (KSâ‰¥0.2): {white['severe_drift']} ({white['severe_drift']/white['total_features']*100:.1f}%)\n")
            f.write(f"- **æä¸¥é‡åç§»ç‰¹å¾** (KSâ‰¥0.4): {white['extreme_drift']} ({white['extreme_drift']/white['total_features']*100:.1f}%)\n")
            f.write(f"- **å¹³å‡KSç»Ÿè®¡é‡**: {white['avg_ks']:.4f}\n")
            f.write(f"- **æœ€å¤§KSç»Ÿè®¡é‡**: {white['max_ks']:.4f}\n\n")
            
            f.write("### é»‘æ ·æœ¬åç§»æƒ…å†µ (trainé»‘æ ·æœ¬ vs bad250623)\n")
            black = drift_summary['black_samples']
            f.write(f"- **æ€»ç‰¹å¾æ•°**: {black['total_features']}\n")
            f.write(f"- **æ˜¾è‘—åç§»ç‰¹å¾**: {black['significant_drift']} ({black['significant_drift']/black['total_features']*100:.1f}%)\n")
            f.write(f"- **ä¸¥é‡åç§»ç‰¹å¾** (KSâ‰¥0.2): {black['severe_drift']} ({black['severe_drift']/black['total_features']*100:.1f}%)\n")
            f.write(f"- **æä¸¥é‡åç§»ç‰¹å¾** (KSâ‰¥0.4): {black['extreme_drift']} ({black['extreme_drift']/black['total_features']*100:.1f}%)\n")
            f.write(f"- **å¹³å‡KSç»Ÿè®¡é‡**: {black['avg_ks']:.4f}\n")
            f.write(f"- **æœ€å¤§KSç»Ÿè®¡é‡**: {black['max_ks']:.4f}\n\n")
            
            f.write("## ğŸ” åç§»åŸå› åˆ†æ\n\n")
            f.write("### å¯èƒ½çš„åŸå› :\n")
            f.write("1. **æ—¶é—´åç§»**: æ•°æ®æ”¶é›†æ—¶é—´ä¸åŒï¼Œæ¶æ„è½¯ä»¶æŠ€æœ¯æ¼”è¿›\n")
            f.write("2. **æ¥æºåç§»**: ä¸åŒçš„æ•°æ®æºæˆ–æ”¶é›†æ–¹æ³•\n")
            f.write("3. **æ ‡æ³¨åç§»**: æ ‡æ³¨æ ‡å‡†æˆ–è´¨é‡çš„å˜åŒ–\n")
            f.write("4. **é¢„å¤„ç†åç§»**: ç‰¹å¾æå–æ–¹æ³•çš„å·®å¼‚\n\n")
            
            f.write("## ğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ\n\n")
            f.write("### çŸ­æœŸè§£å†³æ–¹æ¡ˆ:\n")
            f.write("1. **ç‰¹å¾é€‰æ‹©**: ç§»é™¤åç§»ä¸¥é‡çš„ç‰¹å¾\n")
            f.write("2. **æ•°æ®æ ‡å‡†åŒ–**: å¯¹åç§»ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†\n")
            f.write("3. **åŸŸé€‚åº”**: ä½¿ç”¨åŸŸé€‚åº”æŠ€æœ¯å‡å°‘åç§»å½±å“\n\n")
            
            f.write("### é•¿æœŸè§£å†³æ–¹æ¡ˆ:\n")
            f.write("1. **æ•°æ®é‡æ–°æ”¶é›†**: ç¡®ä¿æ•°æ®æ”¶é›†æ ‡å‡†ä¸€è‡´\n")
            f.write("2. **ç‰¹å¾å·¥ç¨‹**: è®¾è®¡æ›´ç¨³å®šçš„ç‰¹å¾\n")
            f.write("3. **æŒç»­ç›‘æ§**: å»ºç«‹ç‰¹å¾åç§»ç›‘æ§æœºåˆ¶\n")
        
        print(f"âœ… åç§»åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åç§»åˆ†æ"""
        print("ğŸ¯ ç‰¹å¾åç§»æ·±åº¦åˆ†æ")
        print("=" * 50)
        
        self.load_data()
        drift_summary, white_ks, black_ks = self.analyze_drift_severity()
        self.create_drift_visualization(white_ks, black_ks)
        self.generate_drift_report(drift_summary)
        
        print(f"\nğŸ‰ åç§»åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ° featuretrain/ æ–‡ä»¶å¤¹")

if __name__ == "__main__":
    analyzer = FeatureDriftAnalyzer()
    analyzer.run_analysis()
