#!/usr/bin/env python3
"""
ä¸‰ç»´ç‰¹å¾è¯„ä¼°ç³»ç»Ÿ
ç»“åˆSHAPå¯è§£é‡Šæ€§ã€KSç¨³å®šæ€§ã€åˆ¤åˆ«åŠ›åˆ†æ
ä¸ºæ¯ä¸ªç‰¹å¾æ‰“å‡º"è§£é‡Šæ€§ + ç¨³å®šæ€§ + åˆ¤åˆ«åŠ›"ä¸‰ç»´æ ‡ç­¾
è¾“å‡ºç‰¹å¾å¤„ç†ç­–ç•¥å’Œé£é™©é›·è¾¾å›¾
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import matplotlib
from math import pi
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

warnings.filterwarnings('ignore')

class ThreeDimensionalFeatureAssessment:
    def __init__(self):
        """åˆå§‹åŒ–ä¸‰ç»´ç‰¹å¾è¯„ä¼°ç³»ç»Ÿ"""
        self.output_dir = Path('featuretrain')
        
        # æ•°æ®å­˜å‚¨
        self.feature_scores = {}
        self.feature_strategies = {}
        
    def load_comprehensive_data(self):
        """åŠ è½½ç»¼åˆåˆ†ææ•°æ®"""
        print("ğŸ“Š åŠ è½½ä¸‰ç»´ç‰¹å¾è¯„ä¼°æ•°æ®...")
        
        try:
            # 1. åŠ è½½ç‰¹å¾æ¼‚ç§»æ•°æ®ï¼ˆç¨³å®šæ€§ï¼‰
            self.white_drift = pd.read_csv('featuretrain/ks_analysis_white_comparison.csv')
            self.black_drift = pd.read_csv('featuretrain/ks_analysis_black_comparison.csv')
            
            # 2. åŠ è½½SHAPåˆ†ææ•°æ®ï¼ˆå¯è§£é‡Šæ€§ï¼‰
            self.shap_pattern = pd.read_excel('feature_analysis/shap_pattern_analysis.xlsx')
            self.shap_problematic = pd.read_excel('feature_analysis/shap_problematic_features.xlsx')
            self.integrated_results = pd.read_excel('feature_analysis/integrated_analysis_results.xlsx')
            
            # 3. åŠ è½½è¯¯æŠ¥åˆ†ææ•°æ®ï¼ˆåˆ¤åˆ«åŠ›ï¼‰
            self.comprehensive_ks = pd.read_excel('feature_analysis/comprehensive_ks_analysis.xlsx')
            
            print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def calculate_three_dimensional_scores(self):
        """è®¡ç®—ä¸‰ç»´è¯„åˆ†ï¼šè§£é‡Šæ€§ + ç¨³å®šæ€§ + åˆ¤åˆ«åŠ›"""
        print("\nğŸ¯ è®¡ç®—ä¸‰ç»´ç‰¹å¾è¯„åˆ†...")
        
        feature_assessments = []
        
        # è·å–æ‰€æœ‰ç‰¹å¾åˆ—è¡¨
        features = self.white_drift['feature'].tolist()
        
        for feature in features:
            try:
                # 1. ç¨³å®šæ€§è¯„åˆ† (Stability Score)
                white_row = self.white_drift[self.white_drift['feature'] == feature].iloc[0]
                black_row = self.black_drift[self.black_drift['feature'] == feature].iloc[0]
                
                # ç¨³å®šæ€§ = 1 - å¹³å‡KSæ¼‚ç§» (è¶Šå°è¶Šç¨³å®š)
                avg_drift = (white_row['ks_statistic'] + black_row['ks_statistic']) / 2
                stability_score = max(0, 1 - avg_drift)  # 0-1èŒƒå›´
                
                # 2. åˆ¤åˆ«åŠ›è¯„åˆ† (Discriminative Power)
                # åŸºäºé»‘ç™½æ ·æœ¬åˆ†ç¦»èƒ½åŠ›
                white_mean = white_row['train_white_mean']
                black_mean = black_row['train_black_mean']
                white_std = white_row['train_white_std']
                black_std = black_row['train_black_std']
                
                # è®¡ç®—æ•ˆåº”å¤§å°ä½œä¸ºåˆ¤åˆ«åŠ›æŒ‡æ ‡
                mean_diff = abs(white_mean - black_mean)
                pooled_std = np.sqrt((white_std**2 + black_std**2) / 2)
                discriminative_power = min(1, mean_diff / pooled_std if pooled_std > 0 else 0)
                
                # 3. å¯è§£é‡Šæ€§è¯„åˆ† (Interpretability Score)
                interpretability_score = 0
                shap_risk_flag = False
                shap_importance = 0
                
                # ä»SHAPæ¨¡å¼åˆ†æè·å–å¯è§£é‡Šæ€§
                shap_row = self.shap_pattern[self.shap_pattern['feature'] == feature]
                if not shap_row.empty:
                    # SHAPé‡è¦æ€§
                    if 'misc_importance' in shap_row.columns:
                        shap_importance = abs(shap_row['misc_importance'].iloc[0])
                    
                    # SHAPå¯è§£é‡Šæ€§è¯„åˆ†
                    if 'misc_closer_to_black_shap' in shap_row.columns:
                        closer_to_black = shap_row['misc_closer_to_black_shap'].iloc[0]
                        if closer_to_black:
                            interpretability_score = 0.3  # ä½å¯è§£é‡Šæ€§ï¼ˆå®¹æ˜“è¯¯å¯¼ï¼‰
                        else:
                            interpretability_score = 0.8  # é«˜å¯è§£é‡Šæ€§
                    
                    # SHAPç›¸ä¼¼åº¦è°ƒæ•´
                    if 'misc_black_shap_similarity' in shap_row.columns:
                        similarity = shap_row['misc_black_shap_similarity'].iloc[0]
                        if not pd.isna(similarity):
                            # ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œå¯è§£é‡Šæ€§è¶Šä½
                            interpretability_score = max(0.1, 1 - similarity)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºSHAPé—®é¢˜ç‰¹å¾
                if feature in self.shap_problematic['feature'].values:
                    shap_risk_flag = True
                    interpretability_score = min(interpretability_score, 0.2)  # å¤§å¹…é™ä½å¯è§£é‡Šæ€§
                
                # 4. ç»¼åˆé£é™©è¯„ä¼°
                # ä»integrated_resultsè·å–é£é™©è¯„åˆ†
                risk_score = 0
                integrated_row = self.integrated_results[self.integrated_results['feature'] == feature]
                if not integrated_row.empty and 'risk_score' in integrated_row.columns:
                    risk_score = integrated_row['risk_score'].iloc[0]
                    if pd.isna(risk_score):
                        risk_score = 0
                
                # 5. ç‰¹å¾åˆ†ç±»
                feature_type = self.classify_feature_type(feature)
                
                # 6. è®¡ç®—ç»¼åˆè¯„åˆ†
                # ç¨³å®šæ€§æƒé‡40%ï¼Œåˆ¤åˆ«åŠ›æƒé‡35%ï¼Œå¯è§£é‡Šæ€§æƒé‡25%
                overall_score = (stability_score * 0.4 + 
                               discriminative_power * 0.35 + 
                               interpretability_score * 0.25)
                
                feature_assessments.append({
                    'feature': feature,
                    'stability_score': stability_score,
                    'discriminative_power': discriminative_power,
                    'interpretability_score': interpretability_score,
                    'overall_score': overall_score,
                    'white_drift_ks': white_row['ks_statistic'],
                    'black_drift_ks': black_row['ks_statistic'],
                    'avg_drift': avg_drift,
                    'shap_importance': shap_importance,
                    'shap_risk_flag': shap_risk_flag,
                    'risk_score': risk_score,
                    'feature_type': feature_type,
                    'white_mean': white_mean,
                    'black_mean': black_mean,
                    'mean_difference': mean_diff
                })
                
            except Exception as e:
                print(f"    âš ï¸  ç‰¹å¾ {feature} è¯„ä¼°å¤±è´¥: {e}")
                continue
        
        self.feature_scores = pd.DataFrame(feature_assessments)
        self.feature_scores = self.feature_scores.sort_values('overall_score', ascending=False)
        
        # ä¿å­˜ä¸‰ç»´è¯„åˆ†ç»“æœ
        scores_file = self.output_dir / 'three_dimensional_feature_scores.csv'
        self.feature_scores.to_csv(scores_file, index=False, encoding='utf-8')
        
        print(f"âœ… ä¸‰ç»´ç‰¹å¾è¯„åˆ†å®Œæˆ: {scores_file}")
        print(f"   - æ€»ç‰¹å¾æ•°: {len(self.feature_scores)}")
        print(f"   - é«˜é£é™©ç‰¹å¾: {self.feature_scores['shap_risk_flag'].sum()}")
        
        return self.feature_scores
    
    def classify_feature_type(self, feature):
        """åˆ†ç±»ç‰¹å¾ç±»å‹"""
        feature_lower = feature.lower()
        
        if any(keyword in feature_lower for keyword in ['line', 'proc', 'num', 'cnt']):
            return 'ä»£ç ç»“æ„'
        elif any(keyword in feature_lower for keyword in ['shell', 'create', 'open', 'close', 'write']):
            return 'VBAå‡½æ•°'
        elif any(keyword in feature_lower for keyword in ['cmd', 'exe', 'dll', 'registry']):
            return 'å¯ç–‘å…³é”®è¯'
        else:
            return 'å…¶ä»–'
    
    def generate_feature_strategies(self):
        """ç”Ÿæˆç‰¹å¾å¤„ç†ç­–ç•¥"""
        print("\nğŸ’¡ ç”Ÿæˆç‰¹å¾å¤„ç†ç­–ç•¥...")
        
        strategies = {
            'keep_core': [],           # ä¿ç•™æ ¸å¿ƒç‰¹å¾
            'remove_risky': [],        # ç§»é™¤é«˜é£é™©ç‰¹å¾
            'combine_weak': [],        # ç»„åˆå¼±ç‰¹å¾
            'rule_control': [],        # è§„åˆ™æ§åˆ¶ç‰¹å¾
            'monitor_unstable': []     # ç›‘æ§ä¸ç¨³å®šç‰¹å¾
        }
        
        for _, row in self.feature_scores.iterrows():
            feature = row['feature']
            stability = row['stability_score']
            discriminative = row['discriminative_power']
            interpretability = row['interpretability_score']
            overall = row['overall_score']
            shap_risk = row['shap_risk_flag']
            
            # å†³ç­–é€»è¾‘
            if shap_risk or interpretability < 0.3:
                # SHAPé«˜é£é™©æˆ–ä½å¯è§£é‡Šæ€§ -> ç§»é™¤
                strategies['remove_risky'].append({
                    'feature': feature,
                    'reason': 'SHAPé«˜é£é™©' if shap_risk else 'ä½å¯è§£é‡Šæ€§',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif stability > 0.8 and discriminative > 0.6 and interpretability > 0.6:
                # ä¸‰ç»´éƒ½é«˜ -> ä¿ç•™æ ¸å¿ƒ
                strategies['keep_core'].append({
                    'feature': feature,
                    'reason': 'ä¸‰ç»´è¯„åˆ†å‡ä¼˜ç§€',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif stability < 0.5:
                # ç¨³å®šæ€§å·® -> ç›‘æ§
                strategies['monitor_unstable'].append({
                    'feature': feature,
                    'reason': 'ç¨³å®šæ€§å·®ï¼Œéœ€è¦ç›‘æ§',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif discriminative < 0.3:
                # åˆ¤åˆ«åŠ›å·® -> ç»„åˆ
                strategies['combine_weak'].append({
                    'feature': feature,
                    'reason': 'åˆ¤åˆ«åŠ›å¼±ï¼Œå»ºè®®ç»„åˆ',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif interpretability > 0.7 and discriminative > 0.4:
                # å¯è§£é‡Šæ€§å¥½ï¼Œåˆ¤åˆ«åŠ›ä¸­ç­‰ -> è§„åˆ™æ§åˆ¶
                strategies['rule_control'].append({
                    'feature': feature,
                    'reason': 'é€‚åˆè§„åˆ™æ§åˆ¶',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            else:
                # å…¶ä»–æƒ…å†µ -> æ ¹æ®ç»¼åˆè¯„åˆ†å†³å®š
                if overall > 0.6:
                    strategies['keep_core'].append({
                        'feature': feature,
                        'reason': 'ç»¼åˆè¯„åˆ†è‰¯å¥½',
                        'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                    })
                else:
                    strategies['combine_weak'].append({
                        'feature': feature,
                        'reason': 'ç»¼åˆè¯„åˆ†ä¸€èˆ¬ï¼Œå»ºè®®ç»„åˆ',
                        'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                    })
        
        self.feature_strategies = strategies
        
        # ä¿å­˜ç­–ç•¥ç»“æœ
        strategies_file = self.output_dir / 'feature_processing_strategies.json'
        import json
        with open(strategies_file, 'w', encoding='utf-8') as f:
            json.dump(strategies, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç‰¹å¾å¤„ç†ç­–ç•¥ç”Ÿæˆå®Œæˆ: {strategies_file}")
        print(f"   - ä¿ç•™æ ¸å¿ƒ: {len(strategies['keep_core'])}")
        print(f"   - ç§»é™¤é«˜é£é™©: {len(strategies['remove_risky'])}")
        print(f"   - ç»„åˆå¼±ç‰¹å¾: {len(strategies['combine_weak'])}")
        print(f"   - è§„åˆ™æ§åˆ¶: {len(strategies['rule_control'])}")
        print(f"   - ç›‘æ§ä¸ç¨³å®š: {len(strategies['monitor_unstable'])}")
        
        return strategies
    
    def create_feature_risk_radar(self, top_n=20):
        """åˆ›å»ºç‰¹å¾é£é™©é›·è¾¾å›¾"""
        print(f"\nğŸ“ˆ ç”Ÿæˆç‰¹å¾é£é™©é›·è¾¾å›¾ (å‰{top_n}ä¸ªç‰¹å¾)...")
        
        # é€‰æ‹©å‰Nä¸ªç‰¹å¾
        top_features = self.feature_scores.head(top_n)
        
        # åˆ›å»ºé›·è¾¾å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12), subplot_kw=dict(projection='polar'))
        axes = axes.flatten()
        
        # é›·è¾¾å›¾å‚æ•°
        categories = ['ç¨³å®šæ€§', 'åˆ¤åˆ«åŠ›', 'å¯è§£é‡Šæ€§']
        N = len(categories)
        
        # è®¡ç®—è§’åº¦
        angles = [n / float(N) * 2 * pi for n in range(N)]
        angles += angles[:1]  # é—­åˆ
        
        # 1. é«˜é£é™©ç‰¹å¾é›·è¾¾å›¾
        ax1 = axes[0]
        risky_features = self.feature_scores[self.feature_scores['shap_risk_flag'] == True].head(5)
        
        for i, (_, row) in enumerate(risky_features.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]  # é—­åˆ
            
            ax1.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax1.fill(angles, values, alpha=0.1)
        
        ax1.set_xticks(angles[:-1])
        ax1.set_xticklabels(categories)
        ax1.set_ylim(0, 1)
        ax1.set_title('é«˜é£é™©ç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax1.grid(True)
        
        # 2. æ ¸å¿ƒä¿ç•™ç‰¹å¾é›·è¾¾å›¾
        ax2 = axes[1]
        core_features = self.feature_scores[
            (self.feature_scores['stability_score'] > 0.7) & 
            (self.feature_scores['discriminative_power'] > 0.5) &
            (self.feature_scores['shap_risk_flag'] == False)
        ].head(5)
        
        for i, (_, row) in enumerate(core_features.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]
            
            ax2.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax2.fill(angles, values, alpha=0.1)
        
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(categories)
        ax2.set_ylim(0, 1)
        ax2.set_title('æ ¸å¿ƒä¿ç•™ç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax2.grid(True)
        
        # 3. ä¸ç¨³å®šç‰¹å¾é›·è¾¾å›¾
        ax3 = axes[2]
        unstable_features = self.feature_scores[self.feature_scores['stability_score'] < 0.5].head(5)
        
        for i, (_, row) in enumerate(unstable_features.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]
            
            ax3.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax3.fill(angles, values, alpha=0.1)
        
        ax3.set_xticks(angles[:-1])
        ax3.set_xticklabels(categories)
        ax3.set_ylim(0, 1)
        ax3.set_title('ä¸ç¨³å®šç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax3.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax3.grid(True)
        
        # 4. ç»¼åˆè¯„åˆ†æœ€é«˜ç‰¹å¾é›·è¾¾å›¾
        ax4 = axes[3]
        top_overall = self.feature_scores.head(5)
        
        for i, (_, row) in enumerate(top_overall.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]
            
            ax4.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax4.fill(angles, values, alpha=0.1)
        
        ax4.set_xticks(angles[:-1])
        ax4.set_xticklabels(categories)
        ax4.set_ylim(0, 1)
        ax4.set_title('ç»¼åˆè¯„åˆ†æœ€é«˜ç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax4.grid(True)
        
        plt.tight_layout()
        
        # ä¿å­˜é›·è¾¾å›¾
        radar_file = self.output_dir / 'feature_risk_radar_charts.png'
        plt.savefig(radar_file, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… ç‰¹å¾é£é™©é›·è¾¾å›¾å·²ä¿å­˜: {radar_file}")
        
        return radar_file

    def create_comprehensive_visualization(self):
        """åˆ›å»ºç»¼åˆå¯è§†åŒ–åˆ†æ"""
        print("\nğŸ“Š ç”Ÿæˆç»¼åˆä¸‰ç»´åˆ†æå¯è§†åŒ–...")

        fig, axes = plt.subplots(2, 3, figsize=(20, 12))

        # 1. ä¸‰ç»´æ•£ç‚¹å›¾
        ax1 = axes[0, 0]
        scatter = ax1.scatter(self.feature_scores['stability_score'],
                             self.feature_scores['discriminative_power'],
                             c=self.feature_scores['interpretability_score'],
                             s=60, alpha=0.7, cmap='RdYlGn')
        ax1.set_xlabel('ç¨³å®šæ€§è¯„åˆ†')
        ax1.set_ylabel('åˆ¤åˆ«åŠ›è¯„åˆ†')
        ax1.set_title('ä¸‰ç»´ç‰¹å¾è¯„åˆ†æ•£ç‚¹å›¾')
        plt.colorbar(scatter, ax=ax1, label='å¯è§£é‡Šæ€§è¯„åˆ†')
        ax1.grid(True, alpha=0.3)

        # 2. ç‰¹å¾ç­–ç•¥åˆ†å¸ƒé¥¼å›¾
        ax2 = axes[0, 1]
        strategy_counts = {
            'ä¿ç•™æ ¸å¿ƒ': len(self.feature_strategies['keep_core']),
            'ç§»é™¤é«˜é£é™©': len(self.feature_strategies['remove_risky']),
            'ç»„åˆå¼±ç‰¹å¾': len(self.feature_strategies['combine_weak']),
            'è§„åˆ™æ§åˆ¶': len(self.feature_strategies['rule_control']),
            'ç›‘æ§ä¸ç¨³å®š': len(self.feature_strategies['monitor_unstable'])
        }

        colors = ['green', 'red', 'orange', 'blue', 'purple']
        ax2.pie(strategy_counts.values(), labels=strategy_counts.keys(),
               autopct='%1.1f%%', colors=colors, startangle=90)
        ax2.set_title('ç‰¹å¾å¤„ç†ç­–ç•¥åˆ†å¸ƒ')

        # 3. é£é™©è¯„åˆ†åˆ†å¸ƒ
        ax3 = axes[0, 2]
        risk_categories = []
        for _, row in self.feature_scores.iterrows():
            if row['shap_risk_flag']:
                risk_categories.append('SHAPé«˜é£é™©')
            elif row['overall_score'] > 0.7:
                risk_categories.append('ä½é£é™©')
            elif row['overall_score'] > 0.4:
                risk_categories.append('ä¸­ç­‰é£é™©')
            else:
                risk_categories.append('é«˜é£é™©')

        risk_counts = pd.Series(risk_categories).value_counts()
        ax3.bar(risk_counts.index, risk_counts.values,
               color=['red', 'orange', 'yellow', 'green'])
        ax3.set_title('ç‰¹å¾é£é™©ç­‰çº§åˆ†å¸ƒ')
        ax3.set_ylabel('ç‰¹å¾æ•°é‡')
        plt.setp(ax3.get_xticklabels(), rotation=45)

        # 4. ç‰¹å¾ç±»å‹vsè¯„åˆ†
        ax4 = axes[1, 0]
        feature_types = self.feature_scores['feature_type'].unique()
        type_scores = []

        for ftype in feature_types:
            type_data = self.feature_scores[self.feature_scores['feature_type'] == ftype]
            type_scores.append([
                type_data['stability_score'].mean(),
                type_data['discriminative_power'].mean(),
                type_data['interpretability_score'].mean()
            ])

        x = np.arange(len(feature_types))
        width = 0.25

        ax4.bar(x - width, [scores[0] for scores in type_scores], width,
               label='ç¨³å®šæ€§', alpha=0.8)
        ax4.bar(x, [scores[1] for scores in type_scores], width,
               label='åˆ¤åˆ«åŠ›', alpha=0.8)
        ax4.bar(x + width, [scores[2] for scores in type_scores], width,
               label='å¯è§£é‡Šæ€§', alpha=0.8)

        ax4.set_xlabel('ç‰¹å¾ç±»å‹')
        ax4.set_ylabel('å¹³å‡è¯„åˆ†')
        ax4.set_title('ä¸åŒç±»å‹ç‰¹å¾çš„ä¸‰ç»´è¯„åˆ†å¯¹æ¯”')
        ax4.set_xticks(x)
        ax4.set_xticklabels(feature_types, rotation=45)
        ax4.legend()
        ax4.grid(True, alpha=0.3)

        # 5. ç»¼åˆè¯„åˆ†æ’å
        ax5 = axes[1, 1]
        top_15 = self.feature_scores.head(15)
        y_pos = range(len(top_15))

        bars = ax5.barh(y_pos, top_15['overall_score'], alpha=0.7)

        # æ ¹æ®é£é™©æ ‡è®°é¢œè‰²
        for i, (_, row) in enumerate(top_15.iterrows()):
            if row['shap_risk_flag']:
                bars[i].set_color('red')
            elif row['overall_score'] > 0.7:
                bars[i].set_color('green')
            else:
                bars[i].set_color('orange')

        ax5.set_yticks(y_pos)
        ax5.set_yticklabels(top_15['feature'], fontsize=9)
        ax5.set_xlabel('ç»¼åˆè¯„åˆ†')
        ax5.set_title('å‰15ä¸ªç‰¹å¾ç»¼åˆè¯„åˆ†æ’å')
        ax5.grid(True, alpha=0.3)
        ax5.invert_yaxis()

        # 6. ç¨³å®šæ€§vsåˆ¤åˆ«åŠ›è±¡é™å›¾
        ax6 = axes[1, 2]

        # æ ¹æ®SHAPé£é™©æ ‡è®°é¢œè‰²
        colors = ['red' if risk else 'blue' for risk in self.feature_scores['shap_risk_flag']]

        ax6.scatter(self.feature_scores['stability_score'],
                   self.feature_scores['discriminative_power'],
                   c=colors, alpha=0.6, s=50)

        # æ·»åŠ è±¡é™åˆ†å‰²çº¿
        ax6.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)
        ax6.axvline(x=0.5, color='gray', linestyle='--', alpha=0.7)

        # æ·»åŠ è±¡é™æ ‡ç­¾
        ax6.text(0.75, 0.75, 'ç†æƒ³åŒºåŸŸ\n(é«˜ç¨³å®š+é«˜åˆ¤åˆ«)', ha='center', va='center',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.7))
        ax6.text(0.25, 0.75, 'éœ€è¦å·¥ç¨‹\n(ä½ç¨³å®š+é«˜åˆ¤åˆ«)', ha='center', va='center',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.7))
        ax6.text(0.75, 0.25, 'éœ€è¦ç»„åˆ\n(é«˜ç¨³å®š+ä½åˆ¤åˆ«)', ha='center', va='center',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        ax6.text(0.25, 0.25, 'è€ƒè™‘ç§»é™¤\n(ä½ç¨³å®š+ä½åˆ¤åˆ«)', ha='center', va='center',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral", alpha=0.7))

        ax6.set_xlabel('ç¨³å®šæ€§è¯„åˆ†')
        ax6.set_ylabel('åˆ¤åˆ«åŠ›è¯„åˆ†')
        ax6.set_title('ç¨³å®šæ€§vsåˆ¤åˆ«åŠ›è±¡é™åˆ†æ\n(çº¢è‰²=SHAPé«˜é£é™©)')
        ax6.grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜ç»¼åˆå¯è§†åŒ–
        viz_file = self.output_dir / 'three_dimensional_comprehensive_analysis.png'
        plt.savefig(viz_file, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()

        print(f"âœ… ç»¼åˆä¸‰ç»´åˆ†æå¯è§†åŒ–å·²ä¿å­˜: {viz_file}")

        return viz_file

    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆä¸‰ç»´è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“„ ç”Ÿæˆä¸‰ç»´ç‰¹å¾è¯„ä¼°æœ€ç»ˆæŠ¥å‘Š...")

        report_file = self.output_dir / 'three_dimensional_feature_assessment_report.md'

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ä¸‰ç»´ç‰¹å¾è¯„ä¼°æœ€ç»ˆæŠ¥å‘Š\n\n")
            f.write("## ğŸ¯ è¯„ä¼°ç»´åº¦\n\n")
            f.write("æœ¬æŠ¥å‘ŠåŸºäºä¸‰ä¸ªæ ¸å¿ƒç»´åº¦å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œå…¨é¢è¯„ä¼°ï¼š\n\n")
            f.write("1. **ç¨³å®šæ€§ (Stability)**: åŸºäºKSæ£€éªŒçš„ç‰¹å¾æ¼‚ç§»åˆ†æ\n")
            f.write("2. **åˆ¤åˆ«åŠ› (Discriminative Power)**: åŸºäºæ•ˆåº”å¤§å°çš„é»‘ç™½æ ·æœ¬åˆ†ç¦»èƒ½åŠ›\n")
            f.write("3. **å¯è§£é‡Šæ€§ (Interpretability)**: åŸºäºSHAPåˆ†æçš„æ¨¡å‹å†³ç­–å¯è§£é‡Šæ€§\n\n")

            f.write("## ğŸ“Š è¯„ä¼°ç»“æœç»Ÿè®¡\n\n")
            f.write(f"- **æ€»ç‰¹å¾æ•°**: {len(self.feature_scores)}\n")
            f.write(f"- **SHAPé«˜é£é™©ç‰¹å¾**: {self.feature_scores['shap_risk_flag'].sum()}\n")
            f.write(f"- **é«˜ç¨³å®šæ€§ç‰¹å¾** (>0.7): {len(self.feature_scores[self.feature_scores['stability_score'] > 0.7])}\n")
            f.write(f"- **é«˜åˆ¤åˆ«åŠ›ç‰¹å¾** (>0.6): {len(self.feature_scores[self.feature_scores['discriminative_power'] > 0.6])}\n")
            f.write(f"- **é«˜å¯è§£é‡Šæ€§ç‰¹å¾** (>0.7): {len(self.feature_scores[self.feature_scores['interpretability_score'] > 0.7])}\n\n")

            f.write("## ğŸ† ä¸‰ç»´è¯„åˆ†æœ€ä¼˜ç‰¹å¾ (Top 10)\n\n")
            top_10 = self.feature_scores.head(10)
            for i, (_, row) in enumerate(top_10.iterrows()):
                f.write(f"{i+1}. **`{row['feature']}`** (ç»¼åˆ: {row['overall_score']:.3f})\n")
                f.write(f"   - ç¨³å®šæ€§: {row['stability_score']:.3f} | ")
                f.write(f"åˆ¤åˆ«åŠ›: {row['discriminative_power']:.3f} | ")
                f.write(f"å¯è§£é‡Šæ€§: {row['interpretability_score']:.3f}\n")
                f.write(f"   - ç‰¹å¾ç±»å‹: {row['feature_type']}\n\n")

            f.write("## ğŸ’¡ ç‰¹å¾å¤„ç†ç­–ç•¥\n\n")

            # ä¿ç•™æ ¸å¿ƒç‰¹å¾
            f.write("### âœ… ä¿ç•™æ ¸å¿ƒç‰¹å¾\n")
            f.write("ä»¥ä¸‹ç‰¹å¾ä¸‰ç»´è¯„åˆ†ä¼˜ç§€ï¼Œå»ºè®®ä½œä¸ºæ ¸å¿ƒç‰¹å¾ä¿ç•™ï¼š\n")
            for item in self.feature_strategies['keep_core'][:15]:
                f.write(f"- **`{item['feature']}`**: {item['reason']} ({item['scores']})\n")
            f.write("\n")

            # ç§»é™¤é«˜é£é™©ç‰¹å¾
            f.write("### ğŸ—‘ï¸ ç§»é™¤é«˜é£é™©ç‰¹å¾\n")
            f.write("ä»¥ä¸‹ç‰¹å¾å­˜åœ¨SHAPé£é™©æˆ–å¯è§£é‡Šæ€§é—®é¢˜ï¼Œå»ºè®®ç§»é™¤ï¼š\n")
            for item in self.feature_strategies['remove_risky']:
                f.write(f"- **`{item['feature']}`**: {item['reason']} ({item['scores']})\n")
            f.write("\n")

            # ç»„åˆå¼±ç‰¹å¾
            f.write("### ğŸ”— ç»„åˆå¼±ç‰¹å¾\n")
            f.write("ä»¥ä¸‹ç‰¹å¾åˆ¤åˆ«åŠ›è¾ƒå¼±ï¼Œå»ºè®®è¿›è¡Œç‰¹å¾ç»„åˆï¼š\n")
            for item in self.feature_strategies['combine_weak'][:10]:
                f.write(f"- **`{item['feature']}`**: {item['reason']} ({item['scores']})\n")
            f.write("\n")

            # è§„åˆ™æ§åˆ¶ç‰¹å¾
            f.write("### ğŸ“‹ è§„åˆ™æ§åˆ¶ç‰¹å¾\n")
            f.write("ä»¥ä¸‹ç‰¹å¾é€‚åˆé€šè¿‡è§„åˆ™è¿›è¡Œæ§åˆ¶ï¼š\n")
            for item in self.feature_strategies['rule_control'][:10]:
                f.write(f"- **`{item['feature']}`**: {item['reason']} ({item['scores']})\n")
            f.write("\n")

            # ç›‘æ§ä¸ç¨³å®šç‰¹å¾
            f.write("### ğŸ‘ï¸ ç›‘æ§ä¸ç¨³å®šç‰¹å¾\n")
            f.write("ä»¥ä¸‹ç‰¹å¾ç¨³å®šæ€§è¾ƒå·®ï¼Œéœ€è¦æŒç»­ç›‘æ§ï¼š\n")
            for item in self.feature_strategies['monitor_unstable'][:10]:
                f.write(f"- **`{item['feature']}`**: {item['reason']} ({item['scores']})\n")
            f.write("\n")

            f.write("## ğŸ¯ å®æ–½å»ºè®®\n\n")
            f.write("### çŸ­æœŸè¡ŒåŠ¨ (1-2å‘¨)\n")
            f.write("1. **ç«‹å³ç§»é™¤** SHAPé«˜é£é™©ç‰¹å¾\n")
            f.write("2. **é‡ç‚¹ä¿ç•™** ä¸‰ç»´è¯„åˆ†ä¼˜ç§€çš„æ ¸å¿ƒç‰¹å¾\n")
            f.write("3. **å»ºç«‹ç›‘æ§** ä¸ç¨³å®šç‰¹å¾çš„æ¼‚ç§»æƒ…å†µ\n\n")

            f.write("### ä¸­æœŸä¼˜åŒ– (1-2æœˆ)\n")
            f.write("1. **ç‰¹å¾ç»„åˆ** å¼±åˆ¤åˆ«åŠ›ç‰¹å¾ï¼Œæå‡æ•´ä½“æ•ˆæœ\n")
            f.write("2. **è§„åˆ™å¼•æ“** å¯¹é€‚åˆçš„ç‰¹å¾å»ºç«‹è§„åˆ™æ§åˆ¶æœºåˆ¶\n")
            f.write("3. **A/Bæµ‹è¯•** éªŒè¯ç‰¹å¾ç­–ç•¥çš„å®é™…æ•ˆæœ\n\n")

            f.write("### é•¿æœŸç»´æŠ¤ (æŒç»­)\n")
            f.write("1. **å®šæœŸè¯„ä¼°** ä¸‰ç»´ç‰¹å¾è¯„åˆ†çš„å˜åŒ–\n")
            f.write("2. **åŠ¨æ€è°ƒæ•´** ç‰¹å¾å¤„ç†ç­–ç•¥\n")
            f.write("3. **æŒç»­ç›‘æ§** SHAPå¯è§£é‡Šæ€§å’Œç‰¹å¾ç¨³å®šæ€§\n\n")

            f.write("## ğŸ“ ç”Ÿæˆæ–‡ä»¶\n\n")
            f.write("- `three_dimensional_feature_scores.csv`: è¯¦ç»†ä¸‰ç»´è¯„åˆ†æ•°æ®\n")
            f.write("- `feature_processing_strategies.json`: ç‰¹å¾å¤„ç†ç­–ç•¥\n")
            f.write("- `feature_risk_radar_charts.png`: ç‰¹å¾é£é™©é›·è¾¾å›¾\n")
            f.write("- `three_dimensional_comprehensive_analysis.png`: ç»¼åˆåˆ†æå¯è§†åŒ–\n")
            f.write("- `three_dimensional_feature_assessment_report.md`: æœ¬æŠ¥å‘Š\n")

        print(f"âœ… ä¸‰ç»´ç‰¹å¾è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        return report_file

    def run_three_dimensional_assessment(self):
        """è¿è¡Œå®Œæ•´çš„ä¸‰ç»´ç‰¹å¾è¯„ä¼°"""
        print("ğŸ¯ ä¸‰ç»´ç‰¹å¾è¯„ä¼°ç³»ç»Ÿ")
        print("=" * 70)
        print("è¯„ä¼°ç»´åº¦: è§£é‡Šæ€§ + ç¨³å®šæ€§ + åˆ¤åˆ«åŠ›")
        print("=" * 70)

        # 1. åŠ è½½æ•°æ®
        if not self.load_comprehensive_data():
            return False

        # 2. è®¡ç®—ä¸‰ç»´è¯„åˆ†
        feature_scores = self.calculate_three_dimensional_scores()

        # 3. ç”Ÿæˆå¤„ç†ç­–ç•¥
        strategies = self.generate_feature_strategies()

        # 4. åˆ›å»ºé£é™©é›·è¾¾å›¾
        self.create_feature_risk_radar()

        # 5. åˆ›å»ºç»¼åˆå¯è§†åŒ–
        self.create_comprehensive_visualization()

        # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.generate_final_report()

        print(f"\nğŸ‰ ä¸‰ç»´ç‰¹å¾è¯„ä¼°å®Œæˆï¼")
        print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° featuretrain/ æ–‡ä»¶å¤¹")
        print(f"ğŸ¯ ç‰¹å¾å¤„ç†ç­–ç•¥å·²ç”Ÿæˆï¼Œå¯ç›´æ¥ç”¨äºæ¨¡å‹ä¼˜åŒ–")

        return True

def main():
    """ä¸»å‡½æ•°"""
    assessor = ThreeDimensionalFeatureAssessment()
    success = assessor.run_three_dimensional_assessment()

    if success:
        print("\nâœ… ä¸‰ç»´ç‰¹å¾è¯„ä¼°ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")
        print("ğŸ’¡ è¯·æŸ¥çœ‹ç”Ÿæˆçš„é›·è¾¾å›¾å’ŒæŠ¥å‘Šè·å–è¯¦ç»†çš„ç‰¹å¾å¤„ç†å»ºè®®")
    else:
        print("\nâŒ ä¸‰ç»´ç‰¹å¾è¯„ä¼°å¤±è´¥ï¼")

if __name__ == "__main__":
    main()
