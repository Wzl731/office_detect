#!/usr/bin/env python3
"""
ä¸‰ç»´ç‰¹å¾è¯„ä¼°ç³»ç»Ÿ
ç»“åˆSHAPå¯è§£é‡Šæ€§ã€KSç¨³å®šæ€§ã€åˆ¤åˆ«åŠ›åˆ†æ
ä¸ºæ¯ä¸ªç‰¹å¾æ‰“å‡º"è§£é‡Šæ€§ + ç¨³å®šæ€§ + åˆ¤åˆ«åŠ›"ä¸‰ç»´æ ‡ç­¾
è¾“å‡ºç‰¹å¾å¤„ç†ç­–ç•¥å’Œé£é™©é›·è¾¾å›¾
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import matplotlib
from math import pi
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

warnings.filterwarnings('ignore')

class ThreeDimensionalFeatureAssessment:
    def __init__(self):
        """åˆå§‹åŒ–ä¸‰ç»´ç‰¹å¾è¯„ä¼°ç³»ç»Ÿ"""
        self.output_dir = Path('featuretrain')
        
        # æ•°æ®å­˜å‚¨
        self.feature_scores = {}
        self.feature_strategies = {}
        
    def load_comprehensive_data(self):
        """åŠ è½½ç»¼åˆåˆ†ææ•°æ®"""
        print("ğŸ“Š åŠ è½½ä¸‰ç»´ç‰¹å¾è¯„ä¼°æ•°æ®...")
        
        try:
            # 1. åŠ è½½ç‰¹å¾æ¼‚ç§»æ•°æ®ï¼ˆç¨³å®šæ€§ï¼‰
            self.white_drift = pd.read_csv('featuretrain/ks_analysis_white_comparison.csv')
            self.black_drift = pd.read_csv('featuretrain/ks_analysis_black_comparison.csv')
            
            # 2. åŠ è½½SHAPåˆ†ææ•°æ®ï¼ˆå¯è§£é‡Šæ€§ï¼‰
            self.shap_pattern = pd.read_excel('feature_analysis/shap_pattern_analysis.xlsx')
            self.shap_problematic = pd.read_excel('feature_analysis/shap_problematic_features.xlsx')
            self.integrated_results = pd.read_excel('feature_analysis/integrated_analysis_results.xlsx')
            
            # 3. åŠ è½½è¯¯æŠ¥åˆ†ææ•°æ®ï¼ˆåˆ¤åˆ«åŠ›ï¼‰
            self.comprehensive_ks = pd.read_excel('feature_analysis/comprehensive_ks_analysis.xlsx')
            
            print("âœ… æ•°æ®åŠ è½½å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def calculate_three_dimensional_scores(self):
        """è®¡ç®—ä¸‰ç»´è¯„åˆ†ï¼šè§£é‡Šæ€§ + ç¨³å®šæ€§ + åˆ¤åˆ«åŠ›"""
        print("\nğŸ¯ è®¡ç®—ä¸‰ç»´ç‰¹å¾è¯„åˆ†...")
        
        feature_assessments = []
        
        # è·å–æ‰€æœ‰ç‰¹å¾åˆ—è¡¨
        features = self.white_drift['feature'].tolist()
        
        for feature in features:
            try:
                # 1. ç¨³å®šæ€§è¯„åˆ† (Stability Score)
                white_row = self.white_drift[self.white_drift['feature'] == feature].iloc[0]
                black_row = self.black_drift[self.black_drift['feature'] == feature].iloc[0]
                
                # ç¨³å®šæ€§ = 1 - å¹³å‡KSæ¼‚ç§» (è¶Šå°è¶Šç¨³å®š)
                avg_drift = (white_row['ks_statistic'] + black_row['ks_statistic']) / 2
                stability_score = max(0, 1 - avg_drift)  # 0-1èŒƒå›´
                
                # 2. åˆ¤åˆ«åŠ›è¯„åˆ† (Discriminative Power)
                # åŸºäºé»‘ç™½æ ·æœ¬åˆ†ç¦»èƒ½åŠ›
                white_mean = white_row['train_white_mean']
                black_mean = black_row['train_black_mean']
                white_std = white_row['train_white_std']
                black_std = black_row['train_black_std']
                
                # è®¡ç®—æ•ˆåº”å¤§å°ä½œä¸ºåˆ¤åˆ«åŠ›æŒ‡æ ‡
                mean_diff = abs(white_mean - black_mean)
                pooled_std = np.sqrt((white_std**2 + black_std**2) / 2)
                discriminative_power = min(1, mean_diff / pooled_std if pooled_std > 0 else 0)
                
                # 3. å¯è§£é‡Šæ€§è¯„åˆ† (Interpretability Score)
                interpretability_score = 0
                shap_risk_flag = False
                shap_importance = 0
                
                # ä»SHAPæ¨¡å¼åˆ†æè·å–å¯è§£é‡Šæ€§
                shap_row = self.shap_pattern[self.shap_pattern['feature'] == feature]
                if not shap_row.empty:
                    # SHAPé‡è¦æ€§
                    if 'misc_importance' in shap_row.columns:
                        shap_importance = abs(shap_row['misc_importance'].iloc[0])
                    
                    # SHAPå¯è§£é‡Šæ€§è¯„åˆ†
                    if 'misc_closer_to_black_shap' in shap_row.columns:
                        closer_to_black = shap_row['misc_closer_to_black_shap'].iloc[0]
                        if closer_to_black:
                            interpretability_score = 0.3  # ä½å¯è§£é‡Šæ€§ï¼ˆå®¹æ˜“è¯¯å¯¼ï¼‰
                        else:
                            interpretability_score = 0.8  # é«˜å¯è§£é‡Šæ€§
                    
                    # SHAPç›¸ä¼¼åº¦è°ƒæ•´
                    if 'misc_black_shap_similarity' in shap_row.columns:
                        similarity = shap_row['misc_black_shap_similarity'].iloc[0]
                        if not pd.isna(similarity):
                            # ç›¸ä¼¼åº¦è¶Šé«˜ï¼Œå¯è§£é‡Šæ€§è¶Šä½
                            interpretability_score = max(0.1, 1 - similarity)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºSHAPé—®é¢˜ç‰¹å¾
                if feature in self.shap_problematic['feature'].values:
                    shap_risk_flag = True
                    interpretability_score = min(interpretability_score, 0.2)  # å¤§å¹…é™ä½å¯è§£é‡Šæ€§
                
                # 4. ç»¼åˆé£é™©è¯„ä¼°
                # ä»integrated_resultsè·å–é£é™©è¯„åˆ†
                risk_score = 0
                integrated_row = self.integrated_results[self.integrated_results['feature'] == feature]
                if not integrated_row.empty and 'risk_score' in integrated_row.columns:
                    risk_score = integrated_row['risk_score'].iloc[0]
                    if pd.isna(risk_score):
                        risk_score = 0
                
                # 5. ç‰¹å¾åˆ†ç±»
                feature_type = self.classify_feature_type(feature)
                
                # 6. è®¡ç®—ç»¼åˆè¯„åˆ†
                # ç¨³å®šæ€§æƒé‡40%ï¼Œåˆ¤åˆ«åŠ›æƒé‡35%ï¼Œå¯è§£é‡Šæ€§æƒé‡25%
                overall_score = (stability_score * 0.4 + 
                               discriminative_power * 0.35 + 
                               interpretability_score * 0.25)
                
                feature_assessments.append({
                    'feature': feature,
                    'stability_score': stability_score,
                    'discriminative_power': discriminative_power,
                    'interpretability_score': interpretability_score,
                    'overall_score': overall_score,
                    'white_drift_ks': white_row['ks_statistic'],
                    'black_drift_ks': black_row['ks_statistic'],
                    'avg_drift': avg_drift,
                    'shap_importance': shap_importance,
                    'shap_risk_flag': shap_risk_flag,
                    'risk_score': risk_score,
                    'feature_type': feature_type,
                    'white_mean': white_mean,
                    'black_mean': black_mean,
                    'mean_difference': mean_diff
                })
                
            except Exception as e:
                print(f"    âš ï¸  ç‰¹å¾ {feature} è¯„ä¼°å¤±è´¥: {e}")
                continue
        
        self.feature_scores = pd.DataFrame(feature_assessments)
        self.feature_scores = self.feature_scores.sort_values('overall_score', ascending=False)
        
        # ä¿å­˜ä¸‰ç»´è¯„åˆ†ç»“æœ
        scores_file = self.output_dir / 'three_dimensional_feature_scores.csv'
        self.feature_scores.to_csv(scores_file, index=False, encoding='utf-8')
        
        print(f"âœ… ä¸‰ç»´ç‰¹å¾è¯„åˆ†å®Œæˆ: {scores_file}")
        print(f"   - æ€»ç‰¹å¾æ•°: {len(self.feature_scores)}")
        print(f"   - é«˜é£é™©ç‰¹å¾: {self.feature_scores['shap_risk_flag'].sum()}")
        
        return self.feature_scores
    
    def classify_feature_type(self, feature):
        """åˆ†ç±»ç‰¹å¾ç±»å‹"""
        feature_lower = feature.lower()
        
        if any(keyword in feature_lower for keyword in ['line', 'proc', 'num', 'cnt']):
            return 'ä»£ç ç»“æ„'
        elif any(keyword in feature_lower for keyword in ['shell', 'create', 'open', 'close', 'write']):
            return 'VBAå‡½æ•°'
        elif any(keyword in feature_lower for keyword in ['cmd', 'exe', 'dll', 'registry']):
            return 'å¯ç–‘å…³é”®è¯'
        else:
            return 'å…¶ä»–'
    
    def generate_feature_strategies(self):
        """ç”Ÿæˆç‰¹å¾å¤„ç†ç­–ç•¥"""
        print("\nğŸ’¡ ç”Ÿæˆç‰¹å¾å¤„ç†ç­–ç•¥...")
        
        strategies = {
            'keep_core': [],           # ä¿ç•™æ ¸å¿ƒç‰¹å¾
            'remove_risky': [],        # ç§»é™¤é«˜é£é™©ç‰¹å¾
            'combine_weak': [],        # ç»„åˆå¼±ç‰¹å¾
            'rule_control': [],        # è§„åˆ™æ§åˆ¶ç‰¹å¾
            'monitor_unstable': []     # ç›‘æ§ä¸ç¨³å®šç‰¹å¾
        }
        
        for _, row in self.feature_scores.iterrows():
            feature = row['feature']
            stability = row['stability_score']
            discriminative = row['discriminative_power']
            interpretability = row['interpretability_score']
            overall = row['overall_score']
            shap_risk = row['shap_risk_flag']
            
            # å†³ç­–é€»è¾‘
            if shap_risk or interpretability < 0.3:
                # SHAPé«˜é£é™©æˆ–ä½å¯è§£é‡Šæ€§ -> ç§»é™¤
                strategies['remove_risky'].append({
                    'feature': feature,
                    'reason': 'SHAPé«˜é£é™©' if shap_risk else 'ä½å¯è§£é‡Šæ€§',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif stability > 0.8 and discriminative > 0.6 and interpretability > 0.6:
                # ä¸‰ç»´éƒ½é«˜ -> ä¿ç•™æ ¸å¿ƒ
                strategies['keep_core'].append({
                    'feature': feature,
                    'reason': 'ä¸‰ç»´è¯„åˆ†å‡ä¼˜ç§€',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif stability < 0.5:
                # ç¨³å®šæ€§å·® -> ç›‘æ§
                strategies['monitor_unstable'].append({
                    'feature': feature,
                    'reason': 'ç¨³å®šæ€§å·®ï¼Œéœ€è¦ç›‘æ§',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif discriminative < 0.3:
                # åˆ¤åˆ«åŠ›å·® -> ç»„åˆ
                strategies['combine_weak'].append({
                    'feature': feature,
                    'reason': 'åˆ¤åˆ«åŠ›å¼±ï¼Œå»ºè®®ç»„åˆ',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            elif interpretability > 0.7 and discriminative > 0.4:
                # å¯è§£é‡Šæ€§å¥½ï¼Œåˆ¤åˆ«åŠ›ä¸­ç­‰ -> è§„åˆ™æ§åˆ¶
                strategies['rule_control'].append({
                    'feature': feature,
                    'reason': 'é€‚åˆè§„åˆ™æ§åˆ¶',
                    'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                })
            
            else:
                # å…¶ä»–æƒ…å†µ -> æ ¹æ®ç»¼åˆè¯„åˆ†å†³å®š
                if overall > 0.6:
                    strategies['keep_core'].append({
                        'feature': feature,
                        'reason': 'ç»¼åˆè¯„åˆ†è‰¯å¥½',
                        'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                    })
                else:
                    strategies['combine_weak'].append({
                        'feature': feature,
                        'reason': 'ç»¼åˆè¯„åˆ†ä¸€èˆ¬ï¼Œå»ºè®®ç»„åˆ',
                        'scores': f"ç¨³å®šæ€§:{stability:.2f}, åˆ¤åˆ«åŠ›:{discriminative:.2f}, å¯è§£é‡Šæ€§:{interpretability:.2f}"
                    })
        
        self.feature_strategies = strategies
        
        # ä¿å­˜ç­–ç•¥ç»“æœ
        strategies_file = self.output_dir / 'feature_processing_strategies.json'
        import json
        with open(strategies_file, 'w', encoding='utf-8') as f:
            json.dump(strategies, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç‰¹å¾å¤„ç†ç­–ç•¥ç”Ÿæˆå®Œæˆ: {strategies_file}")
        print(f"   - ä¿ç•™æ ¸å¿ƒ: {len(strategies['keep_core'])}")
        print(f"   - ç§»é™¤é«˜é£é™©: {len(strategies['remove_risky'])}")
        print(f"   - ç»„åˆå¼±ç‰¹å¾: {len(strategies['combine_weak'])}")
        print(f"   - è§„åˆ™æ§åˆ¶: {len(strategies['rule_control'])}")
        print(f"   - ç›‘æ§ä¸ç¨³å®š: {len(strategies['monitor_unstable'])}")
        
        return strategies
    
    def create_feature_risk_radar(self, top_n=20):
        """åˆ›å»ºç‰¹å¾é£é™©é›·è¾¾å›¾"""
        print(f"\nğŸ“ˆ ç”Ÿæˆç‰¹å¾é£é™©é›·è¾¾å›¾ (å‰{top_n}ä¸ªç‰¹å¾)...")
        
        # é€‰æ‹©å‰Nä¸ªç‰¹å¾
        top_features = self.feature_scores.head(top_n)
        
        # åˆ›å»ºé›·è¾¾å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12), subplot_kw=dict(projection='polar'))
        axes = axes.flatten()
        
        # é›·è¾¾å›¾å‚æ•°
        categories = ['ç¨³å®šæ€§', 'åˆ¤åˆ«åŠ›', 'å¯è§£é‡Šæ€§']
        N = len(categories)
        
        # è®¡ç®—è§’åº¦
        angles = [n / float(N) * 2 * pi for n in range(N)]
        angles += angles[:1]  # é—­åˆ
        
        # 1. é«˜é£é™©ç‰¹å¾é›·è¾¾å›¾
        ax1 = axes[0]
        risky_features = self.feature_scores[self.feature_scores['shap_risk_flag'] == True].head(5)
        
        for i, (_, row) in enumerate(risky_features.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]  # é—­åˆ
            
            ax1.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax1.fill(angles, values, alpha=0.1)
        
        ax1.set_xticks(angles[:-1])
        ax1.set_xticklabels(categories)
        ax1.set_ylim(0, 1)
        ax1.set_title('é«˜é£é™©ç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax1.grid(True)
        
        # 2. æ ¸å¿ƒä¿ç•™ç‰¹å¾é›·è¾¾å›¾
        ax2 = axes[1]
        core_features = self.feature_scores[
            (self.feature_scores['stability_score'] > 0.7) & 
            (self.feature_scores['discriminative_power'] > 0.5) &
            (self.feature_scores['shap_risk_flag'] == False)
        ].head(5)
        
        for i, (_, row) in enumerate(core_features.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]
            
            ax2.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax2.fill(angles, values, alpha=0.1)
        
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(categories)
        ax2.set_ylim(0, 1)
        ax2.set_title('æ ¸å¿ƒä¿ç•™ç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax2.grid(True)
        
        # 3. ä¸ç¨³å®šç‰¹å¾é›·è¾¾å›¾
        ax3 = axes[2]
        unstable_features = self.feature_scores[self.feature_scores['stability_score'] < 0.5].head(5)
        
        for i, (_, row) in enumerate(unstable_features.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]
            
            ax3.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax3.fill(angles, values, alpha=0.1)
        
        ax3.set_xticks(angles[:-1])
        ax3.set_xticklabels(categories)
        ax3.set_ylim(0, 1)
        ax3.set_title('ä¸ç¨³å®šç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax3.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax3.grid(True)
        
        # 4. ç»¼åˆè¯„åˆ†æœ€é«˜ç‰¹å¾é›·è¾¾å›¾
        ax4 = axes[3]
        top_overall = self.feature_scores.head(5)
        
        for i, (_, row) in enumerate(top_overall.iterrows()):
            values = [row['stability_score'], row['discriminative_power'], row['interpretability_score']]
            values += values[:1]
            
            ax4.plot(angles, values, 'o-', linewidth=2, label=row['feature'][:15], alpha=0.7)
            ax4.fill(angles, values, alpha=0.1)
        
        ax4.set_xticks(angles[:-1])
        ax4.set_xticklabels(categories)
        ax4.set_ylim(0, 1)
        ax4.set_title('ç»¼åˆè¯„åˆ†æœ€é«˜ç‰¹å¾é›·è¾¾å›¾', size=14, fontweight='bold', pad=20)
        ax4.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax4.grid(True)
        
        plt.tight_layout()
        
        # ä¿å­˜é›·è¾¾å›¾
        radar_file = self.output_dir / 'feature_risk_radar_charts.png'
        plt.savefig(radar_file, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… ç‰¹å¾é£é™©é›·è¾¾å›¾å·²ä¿å­˜: {radar_file}")
        
        return radar_file
