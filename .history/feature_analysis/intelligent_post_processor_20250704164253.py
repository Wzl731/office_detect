#!/usr/bin/env python3
"""
æ™ºèƒ½åå¤„ç†æœºåˆ¶
åŸºäºKSæ£€éªŒå’ŒSHAPåˆ†æç»“æœï¼Œå¯¹æ£€æµ‹ç»“æœè¿›è¡Œæ™ºèƒ½åå¤„ç†
å‡å°‘è¯¯æŠ¥ï¼Œæé«˜æ£€æµ‹å‡†ç¡®æ€§
"""

import pandas as pd
import numpy as np
import joblib
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class IntelligentPostProcessor:
    def __init__(self, analysis_results_dir='./'):
        """
        åˆå§‹åŒ–åå¤„ç†å™¨
        
        Args:
            analysis_results_dir: åˆ†æç»“æœæ–‡ä»¶æ‰€åœ¨ç›®å½•
        """
        self.analysis_dir = Path(analysis_results_dir)
        self.load_analysis_results()
        self.build_post_processing_rules()
        
    def load_analysis_results(self):
        """åŠ è½½æ‰€æœ‰åˆ†æç»“æœ"""
        print("ğŸ“Š åŠ è½½åˆ†æç»“æœ...")
        
        try:
            # 1. åŠ è½½æ•´åˆåˆ†æç»“æœ
            self.integrated_results = pd.read_excel(
                self.analysis_dir / 'integrated_analysis_results.xlsx'
            )
            print("âœ… æ•´åˆåˆ†æç»“æœå·²åŠ è½½")
            
            # 2. åŠ è½½KSæ£€éªŒç»“æœ
            self.ks_results = pd.read_excel(
                self.analysis_dir / 'comprehensive_ks_analysis.xlsx'
            )
            print("âœ… KSæ£€éªŒç»“æœå·²åŠ è½½")
            
            # 3. åŠ è½½SHAPåˆ†æç»“æœ
            self.shap_results = pd.read_excel(
                self.analysis_dir / 'shap_pattern_analysis.xlsx'
            )
            print("âœ… SHAPåˆ†æç»“æœå·²åŠ è½½")
            
            # 4. åŠ è½½ç‰¹å¾å·¥ç¨‹å»ºè®®
            self.recommendations = pd.read_excel(
                self.analysis_dir / 'feature_engineering_recommendations.xlsx'
            )
            print("âœ… ç‰¹å¾å·¥ç¨‹å»ºè®®å·²åŠ è½½")
            
        except FileNotFoundError as e:
            print(f"âŒ ç¼ºå°‘åˆ†æç»“æœæ–‡ä»¶: {e}")
            print("è¯·å…ˆè¿è¡Œå®Œæ•´çš„ç‰¹å¾åˆ†ææµç¨‹")
            raise
    
    def build_post_processing_rules(self):
        """åŸºäºåˆ†æç»“æœæ„å»ºåå¤„ç†è§„åˆ™"""
        print("\nğŸ”§ æ„å»ºåå¤„ç†è§„åˆ™...")
        
        # 1. è¯†åˆ«é«˜é£é™©ç‰¹å¾ï¼ˆå®¹æ˜“å¯¼è‡´è¯¯æŠ¥çš„ç‰¹å¾ï¼‰
        self.high_risk_features = self.integrated_results[
            self.integrated_results['risk_level'] == 'é«˜é£é™©'
        ]['feature'].tolist()
        
        # 2. è¯†åˆ«å¯é ç‰¹å¾ï¼ˆåŒºåˆ†åº¦å¥½çš„ç‰¹å¾ï¼‰
        # æ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
        if 'ks_white_black' in self.integrated_results.columns:
            ks_column = 'ks_white_black'
        elif 'ks_statistic_white_black' in self.integrated_results.columns:
            ks_column = 'ks_statistic_white_black'
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”åˆ—ï¼Œä½¿ç”¨å…¶ä»–æŒ‡æ ‡
            ks_column = None

        if ks_column:
            self.reliable_features = self.integrated_results[
                (self.integrated_results['risk_level'] == 'ä½é£é™©') &
                (self.integrated_results[ks_column] > 0.5)  # ç™½é»‘æ ·æœ¬åŒºåˆ†åº¦å¥½
            ]['feature'].tolist()
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šåªä½¿ç”¨é£é™©ç­‰çº§
            self.reliable_features = self.integrated_results[
                self.integrated_results['risk_level'] == 'ä½é£é™©'
            ]['feature'].tolist()
        
        # 3. æ„å»ºç‰¹å¾æƒé‡è°ƒæ•´è§„åˆ™
        self.feature_weights = {}
        for _, row in self.integrated_results.iterrows():
            feature = row['feature']
            risk_score = row['risk_score']
            
            if risk_score > 0.7:
                self.feature_weights[feature] = 0.3  # é«˜é£é™©ç‰¹å¾é™æƒ
            elif risk_score > 0.5:
                self.feature_weights[feature] = 0.6  # ä¸­é£é™©ç‰¹å¾é€‚åº¦é™æƒ
            else:
                self.feature_weights[feature] = 1.0  # æ­£å¸¸æƒé‡
        
        # 4. æ„å»ºé˜ˆå€¼è°ƒæ•´è§„åˆ™
        self.threshold_adjustments = {}
        for _, row in self.recommendations.iterrows():
            if row['priority'] == 'é«˜':
                feature = row['feature']
                if 'é˜ˆå€¼' in row['recommendation']:
                    self.threshold_adjustments[feature] = 1.5  # æé«˜é˜ˆå€¼
        
        print(f"âœ… è¯†åˆ«é«˜é£é™©ç‰¹å¾: {len(self.high_risk_features)} ä¸ª")
        print(f"âœ… è¯†åˆ«å¯é ç‰¹å¾: {len(self.reliable_features)} ä¸ª")
        print(f"âœ… æ„å»ºæƒé‡è°ƒæ•´è§„åˆ™: {len(self.feature_weights)} ä¸ª")
    
    def post_process_prediction(self, features, original_prediction, original_probability):
        """
        å¯¹å•ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†
        
        Args:
            features: dict, ç‰¹å¾å€¼å­—å…¸ {feature_name: value}
            original_prediction: int, åŸå§‹é¢„æµ‹ç»“æœ (0=è‰¯æ€§, 1=æ¶æ„)
            original_probability: float, åŸå§‹é¢„æµ‹æ¦‚ç‡
            
        Returns:
            dict: åå¤„ç†ç»“æœ
        """
        result = {
            'original_prediction': original_prediction,
            'original_probability': original_probability,
            'adjusted_prediction': original_prediction,
            'adjusted_probability': original_probability,
            'confidence_level': 'medium',
            'post_processing_actions': [],
            'risk_factors': [],
            'protective_factors': []
        }
        
        # 1. è®¡ç®—è°ƒæ•´åçš„é£é™©è¯„åˆ†
        adjusted_score = self._calculate_adjusted_risk_score(features)
        result['adjusted_risk_score'] = adjusted_score
        
        # 2. åº”ç”¨ç‰¹å¾æƒé‡è°ƒæ•´
        weighted_score = self._apply_feature_weights(features, adjusted_score)
        result['weighted_score'] = weighted_score
        
        # 3. æ£€æŸ¥é«˜é£é™©ç‰¹å¾æ¨¡å¼
        risk_factors = self._check_risk_patterns(features)
        result['risk_factors'] = risk_factors
        
        # 4. æ£€æŸ¥ä¿æŠ¤æ€§å› ç´ 
        protective_factors = self._check_protective_patterns(features)
        result['protective_factors'] = protective_factors
        
        # 5. ç»¼åˆå†³ç­–
        final_decision = self._make_final_decision(
            weighted_score, risk_factors, protective_factors, original_probability
        )
        
        result['adjusted_prediction'] = final_decision['prediction']
        result['adjusted_probability'] = final_decision['probability']
        result['confidence_level'] = final_decision['confidence']
        result['post_processing_actions'] = final_decision['actions']
        
        return result
    
    def _calculate_adjusted_risk_score(self, features):
        """åŸºäºåˆ†æç»“æœè®¡ç®—è°ƒæ•´åçš„é£é™©è¯„åˆ†"""
        risk_score = 0.0
        total_weight = 0.0
        
        for feature_name, feature_value in features.items():
            if feature_name in self.integrated_results['feature'].values:
                # è·å–è¯¥ç‰¹å¾çš„åˆ†æç»“æœ
                feature_data = self.integrated_results[
                    self.integrated_results['feature'] == feature_name
                ].iloc[0]
                
                # åŸºäºç‰¹å¾çš„é£é™©è¯„åˆ†å’Œå½“å‰å€¼è®¡ç®—è´¡çŒ®
                feature_risk = feature_data['risk_score']
                
                # æ ‡å‡†åŒ–ç‰¹å¾å€¼ï¼ˆç®€å•çš„min-maxæ ‡å‡†åŒ–ï¼‰
                if feature_value > 0:
                    normalized_value = min(feature_value / 10.0, 1.0)  # ç®€å•æ ‡å‡†åŒ–
                    contribution = feature_risk * normalized_value
                    
                    risk_score += contribution
                    total_weight += feature_risk
        
        return risk_score / (total_weight + 1e-8) if total_weight > 0 else 0.0
    
    def _apply_feature_weights(self, features, base_score):
        """åº”ç”¨ç‰¹å¾æƒé‡è°ƒæ•´"""
        weighted_score = base_score
        
        # æ£€æŸ¥é«˜é£é™©ç‰¹å¾çš„æ¿€æ´»æƒ…å†µ
        high_risk_activation = 0
        for feature in self.high_risk_features:
            if feature in features and features[feature] > 0:
                high_risk_activation += 1
        
        # å¦‚æœé«˜é£é™©ç‰¹å¾å¤§é‡æ¿€æ´»ï¼Œé™ä½æ•´ä½“è¯„åˆ†
        if high_risk_activation > len(self.high_risk_features) * 0.5:
            weighted_score *= 0.7  # é™ä½30%
        
        return weighted_score
    
    def _check_risk_patterns(self, features):
        """æ£€æŸ¥é£é™©æ¨¡å¼"""
        risk_factors = []
        
        # 1. æ£€æŸ¥é«˜é£é™©ç‰¹å¾ç»„åˆ
        high_risk_active = [f for f in self.high_risk_features 
                           if f in features and features[f] > 0]
        
        if len(high_risk_active) >= 3:
            risk_factors.append({
                'type': 'high_risk_feature_combination',
                'description': f'æ¿€æ´»äº†{len(high_risk_active)}ä¸ªé«˜é£é™©ç‰¹å¾',
                'features': high_risk_active,
                'severity': 'high'
            })
        
        # 2. æ£€æŸ¥ç‰¹å®šçš„é—®é¢˜æ¨¡å¼
        # åŸºäºSHAPåˆ†æç»“æœè¯†åˆ«çš„é—®é¢˜æ¨¡å¼
        if 'NUM_PROC' in features and features['NUM_PROC'] > 10:
            if 'AutoOpen' in features and features['AutoOpen'] > 0:
                risk_factors.append({
                    'type': 'complex_autoopen_pattern',
                    'description': 'å¤æ‚VBAä»£ç  + è‡ªåŠ¨æ‰§è¡Œ',
                    'severity': 'medium'
                })
        
        return risk_factors
    
    def _check_protective_patterns(self, features):
        """æ£€æŸ¥ä¿æŠ¤æ€§æ¨¡å¼ï¼ˆé™ä½è¯¯æŠ¥é£é™©çš„å› ç´ ï¼‰"""
        protective_factors = []
        
        # 1. æ£€æŸ¥å¯é ç‰¹å¾çš„æ”¯æŒ
        reliable_active = [f for f in self.reliable_features 
                          if f in features and features[f] == 0]  # å¯é ç‰¹å¾ä¸º0è¡¨ç¤ºè‰¯æ€§
        
        if len(reliable_active) >= 2:
            protective_factors.append({
                'type': 'reliable_features_support',
                'description': f'{len(reliable_active)}ä¸ªå¯é ç‰¹å¾æ”¯æŒè‰¯æ€§åˆ¤æ–­',
                'features': reliable_active,
                'strength': 'medium'
            })
        
        # 2. æ£€æŸ¥åˆæ³•å¤æ‚ä»£ç æ¨¡å¼
        # åŸºäºåˆ†æç»“æœï¼ŒæŸäº›ç‰¹å¾ç»„åˆå¯èƒ½è¡¨ç¤ºåˆæ³•çš„å¤æ‚å·¥å…·
        if ('NUM_PROC' in features and features['NUM_PROC'] > 5 and
            'CreateObject' in features and features['CreateObject'] > 0):
            
            # å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„æ¶æ„è¡Œä¸ºç‰¹å¾ï¼Œå¯èƒ½æ˜¯åˆæ³•å·¥å…·
            malicious_indicators = ['Shell', 'cmd.exe', 'powershell.exe']
            has_malicious = any(f in features and features[f] > 0 
                              for f in malicious_indicators if f in features)
            
            if not has_malicious:
                protective_factors.append({
                    'type': 'legitimate_complex_tool',
                    'description': 'å¯èƒ½æ˜¯åˆæ³•çš„å¤æ‚Excelå·¥å…·',
                    'strength': 'high'
                })
        
        return protective_factors
    
    def _make_final_decision(self, weighted_score, risk_factors, protective_factors, original_prob):
        """ç»¼åˆæ‰€æœ‰å› ç´ åšå‡ºæœ€ç»ˆå†³ç­–"""
        actions = []
        
        # åŸºç¡€è°ƒæ•´
        adjusted_prob = original_prob
        
        # åº”ç”¨é£é™©å› ç´ 
        for risk in risk_factors:
            if risk['severity'] == 'high':
                adjusted_prob *= 1.2  # å¢åŠ 20%
                actions.append(f"åº”ç”¨é«˜é£é™©è°ƒæ•´: {risk['description']}")
            elif risk['severity'] == 'medium':
                adjusted_prob *= 1.1  # å¢åŠ 10%
                actions.append(f"åº”ç”¨ä¸­é£é™©è°ƒæ•´: {risk['description']}")
        
        # åº”ç”¨ä¿æŠ¤æ€§å› ç´ 
        for protection in protective_factors:
            if protection['strength'] == 'high':
                adjusted_prob *= 0.6  # é™ä½40%
                actions.append(f"åº”ç”¨å¼ºä¿æŠ¤è°ƒæ•´: {protection['description']}")
            elif protection['strength'] == 'medium':
                adjusted_prob *= 0.8  # é™ä½20%
                actions.append(f"åº”ç”¨ä¸­ä¿æŠ¤è°ƒæ•´: {protection['description']}")
        
        # é™åˆ¶æ¦‚ç‡èŒƒå›´
        adjusted_prob = max(0.01, min(0.99, adjusted_prob))
        
        # ç¡®å®šæœ€ç»ˆé¢„æµ‹
        final_prediction = 1 if adjusted_prob > 0.5 else 0
        
        # ç¡®å®šç½®ä¿¡åº¦
        if abs(adjusted_prob - 0.5) > 0.4:
            confidence = 'high'
        elif abs(adjusted_prob - 0.5) > 0.2:
            confidence = 'medium'
        else:
            confidence = 'low'
            actions.append("ä½ç½®ä¿¡åº¦é¢„æµ‹ï¼Œå»ºè®®äººå·¥å®¡æ ¸")
        
        return {
            'prediction': final_prediction,
            'probability': adjusted_prob,
            'confidence': confidence,
            'actions': actions
        }
    
    def batch_post_process(self, predictions_df):
        """æ‰¹é‡åå¤„ç†"""
        print("\nğŸ”„ æ‰¹é‡åå¤„ç†...")
        
        results = []
        for idx, row in predictions_df.iterrows():
            # å‡è®¾è¾“å…¥æ ¼å¼åŒ…å«ç‰¹å¾å€¼å’ŒåŸå§‹é¢„æµ‹
            features = {col: row[col] for col in row.index 
                       if col not in ['prediction', 'probability', 'filename']}
            
            result = self.post_process_prediction(
                features, 
                row.get('prediction', 0), 
                row.get('probability', 0.5)
            )
            
            result['filename'] = row.get('filename', f'sample_{idx}')
            results.append(result)
        
        return pd.DataFrame(results)
    
    def save_post_processor(self, filepath='intelligent_post_processor.pkl'):
        """ä¿å­˜åå¤„ç†å™¨é…ç½®"""
        config = {
            'high_risk_features': self.high_risk_features,
            'reliable_features': self.reliable_features,
            'feature_weights': self.feature_weights,
            'threshold_adjustments': self.threshold_adjustments
        }
        
        joblib.dump(config, filepath)
        print(f"âœ… åå¤„ç†å™¨é…ç½®å·²ä¿å­˜åˆ°: {filepath}")
    
    def generate_post_processing_report(self, results_df):
        """ç”Ÿæˆåå¤„ç†æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆåå¤„ç†æŠ¥å‘Š...")
        
        # ç»Ÿè®¡è°ƒæ•´æ•ˆæœ
        original_malicious = (results_df['original_prediction'] == 1).sum()
        adjusted_malicious = (results_df['adjusted_prediction'] == 1).sum()
        
        # è®¡ç®—è°ƒæ•´çš„æ ·æœ¬æ•°
        changed_predictions = (results_df['original_prediction'] != results_df['adjusted_prediction']).sum()
        
        report = f"""
# æ™ºèƒ½åå¤„ç†æŠ¥å‘Š

## å¤„ç†ç»Ÿè®¡
- æ€»æ ·æœ¬æ•°: {len(results_df)}
- åŸå§‹æ¶æ„é¢„æµ‹: {original_malicious}
- è°ƒæ•´åæ¶æ„é¢„æµ‹: {adjusted_malicious}
- é¢„æµ‹æ”¹å˜æ ·æœ¬: {changed_predictions}
- è°ƒæ•´ç‡: {changed_predictions/len(results_df)*100:.1f}%

## è°ƒæ•´æ–¹å‘
- æ¶æ„â†’è‰¯æ€§: {((results_df['original_prediction'] == 1) & (results_df['adjusted_prediction'] == 0)).sum()}
- è‰¯æ€§â†’æ¶æ„: {((results_df['original_prediction'] == 0) & (results_df['adjusted_prediction'] == 1)).sum()}

## ç½®ä¿¡åº¦åˆ†å¸ƒ
- é«˜ç½®ä¿¡åº¦: {(results_df['confidence_level'] == 'high').sum()}
- ä¸­ç½®ä¿¡åº¦: {(results_df['confidence_level'] == 'medium').sum()}
- ä½ç½®ä¿¡åº¦: {(results_df['confidence_level'] == 'low').sum()}
"""
        
        with open('post_processing_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("âœ… åå¤„ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: post_processing_report.md")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    print("ğŸ¯ æ™ºèƒ½åå¤„ç†æœºåˆ¶")
    print("=" * 60)
    
    # åˆå§‹åŒ–åå¤„ç†å™¨
    processor = IntelligentPostProcessor()
    
    # ä¿å­˜é…ç½®
    processor.save_post_processor()
    
    print("\nâœ… æ™ºèƒ½åå¤„ç†å™¨å·²å‡†å¤‡å°±ç»ª!")
    print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print("1. å¯¹å•ä¸ªæ ·æœ¬: processor.post_process_prediction(features, pred, prob)")
    print("2. æ‰¹é‡å¤„ç†: processor.batch_post_process(df)")
    print("3. ç”ŸæˆæŠ¥å‘Š: processor.generate_post_processing_report(results)")

if __name__ == "__main__":
    main()
