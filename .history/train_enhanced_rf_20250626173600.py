#!/usr/bin/env python3
"""
ä½¿ç”¨å¢å¼ºç‰¹å¾é›†è®­ç»ƒRandom Forestæ¨¡å‹
æ·»åŠ è‰¯æ€§ç‰¹å¾ä»¥é™ä½è¯¯æŠ¥ç‡
"""

import numpy as np
import pandas as pd
import pickle
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from original_feature_extractor import OriginalVBAFeatureExtractor

class EnhancedRFTrainer:
    def __init__(self):
        """åˆå§‹åŒ–å¢å¼ºRFè®­ç»ƒå™¨"""
        self.extractor = OriginalVBAFeatureExtractor()
        self.models = {}
        self.scalers = {}
        self.feature_names = None
        
    def extract_features_from_folder(self, folder_path, label):
        """ä»æ–‡ä»¶å¤¹æå–ç‰¹å¾"""
        folder_path = Path(folder_path)
        
        if not folder_path.exists():
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
            return None, None
        
        # è·å–æ‰€æœ‰Officeæ–‡ä»¶
        office_files = []
        for ext in ['*.xls', '*.xlsx', '*.doc', '*.docx']:
            office_files.extend(folder_path.glob(ext))
        
        # å¤„ç†æ— æ‰©å±•åæ–‡ä»¶
        for file_path in folder_path.iterdir():
            if file_path.is_file() and not file_path.suffix:
                office_files.append(file_path)
        
        if not office_files:
            print(f"âŒ åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ°Officeæ–‡ä»¶")
            return None, None
        
        print(f"ğŸ” å¤„ç† {folder_path.name}: {len(office_files)} ä¸ªæ–‡ä»¶")
        
        features_list = []
        labels_list = []
        successful_count = 0
        
        for i, file_path in enumerate(office_files, 1):
            if i % 100 == 0:
                print(f"  å¤„ç†è¿›åº¦: {i}/{len(office_files)}")
            
            # æå–ç‰¹å¾
            features = self.extractor.extract_features_from_file(file_path)
            if features and len(features) == 139:  # æ–°çš„ç‰¹å¾ç»´åº¦
                features_list.append(features[1:])  # å»æ‰æ–‡ä»¶å
                labels_list.append(label)
                successful_count += 1
        
        print(f"âœ… æˆåŠŸæå– {successful_count}/{len(office_files)} ä¸ªæ–‡ä»¶çš„ç‰¹å¾")
        
        if not features_list:
            return None, None
        
        return np.array(features_list), np.array(labels_list)
    
    def prepare_training_data(self, benign_folder, malicious_folder):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # æå–è‰¯æ€§æ ·æœ¬ç‰¹å¾
        benign_features, benign_labels = self.extract_features_from_folder(benign_folder, 0)
        
        # æå–æ¶æ„æ ·æœ¬ç‰¹å¾
        malicious_features, malicious_labels = self.extract_features_from_folder(malicious_folder, 1)
        
        if benign_features is None or malicious_features is None:
            print("âŒ ç‰¹å¾æå–å¤±è´¥")
            return None, None
        
        # åˆå¹¶æ•°æ®
        X = np.vstack([benign_features, malicious_features])
        y = np.hstack([benign_labels, malicious_labels])
        
        print(f"ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(X)}")
        print(f"  è‰¯æ€§æ ·æœ¬: {len(benign_labels)} ({len(benign_labels)/len(y)*100:.1f}%)")
        print(f"  æ¶æ„æ ·æœ¬: {len(malicious_labels)} ({len(malicious_labels)/len(y)*100:.1f}%)")
        print(f"  ç‰¹å¾ç»´åº¦: {X.shape[1]}")
        
        # åˆ›å»ºç‰¹å¾åç§°
        self.feature_names = (['FILENAME'] + 
                             [f'FEATURE_{i+1}' for i in range(77)] + 
                             [f'SUSPICIOUS_{i+1}' for i in range(46)] +
                             [f'BENIGN_{i+1}' for i in range(15)])
        
        return X, y
    
    def train_enhanced_rf(self, X, y, optimize_params=True):
        """è®­ç»ƒå¢å¼ºç‰ˆRandom Forestæ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒå¢å¼ºç‰ˆRandom Forestæ¨¡å‹...")
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        if optimize_params:
            # å‚æ•°ä¼˜åŒ–
            print("ğŸ”§ è¿›è¡Œå‚æ•°ä¼˜åŒ–...")
            param_grid = {
                'n_estimators': [100, 200, 300],
                'max_depth': [10, 15, 20, None],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4],
                'class_weight': ['balanced', None]
            }
            
            rf = RandomForestClassifier(random_state=42)
            grid_search = GridSearchCV(
                rf, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1
            )
            grid_search.fit(X_train, y_train)
            
            best_rf = grid_search.best_estimator_
            print(f"âœ… æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        else:
            # ä½¿ç”¨é»˜è®¤å‚æ•°ä½†é’ˆå¯¹è¯¯æŠ¥ä¼˜åŒ–
            best_rf = RandomForestClassifier(
                n_estimators=200,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                class_weight='balanced',  # å¹³è¡¡ç±»åˆ«æƒé‡
                random_state=42
            )
            best_rf.fit(X_train, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        self._evaluate_model(best_rf, X_train, X_test, y_train, y_test)
        
        # åˆ†æç‰¹å¾é‡è¦æ€§
        self._analyze_feature_importance(best_rf)
        
        self.models['RandomForest'] = best_rf
        return best_rf
    
    def _evaluate_model(self, model, X_train, X_test, y_train, y_test):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        
        # è®­ç»ƒé›†æ€§èƒ½
        train_pred = model.predict(X_train)
        train_score = model.score(X_train, y_train)
        print(f"  è®­ç»ƒé›†å‡†ç¡®ç‡: {train_score:.4f}")
        
        # æµ‹è¯•é›†æ€§èƒ½
        test_pred = model.predict(X_test)
        test_score = model.score(X_test, y_test)
        print(f"  æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.4f}")
        
        # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, test_pred, 
                                  target_names=['è‰¯æ€§', 'æ¶æ„']))
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, test_pred)
        print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
        print(f"  çœŸè´Ÿä¾‹(TN): {cm[0,0]}, å‡æ­£ä¾‹(FP): {cm[0,1]}")
        print(f"  å‡è´Ÿä¾‹(FN): {cm[1,0]}, çœŸæ­£ä¾‹(TP): {cm[1,1]}")
        
        # è¯¯æŠ¥ç‡å’Œæ£€æµ‹ç‡
        fp_rate = cm[0,1] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0
        detection_rate = cm[1,1] / (cm[1,0] + cm[1,1]) if (cm[1,0] + cm[1,1]) > 0 else 0
        
        print(f"  è¯¯æŠ¥ç‡: {fp_rate:.4f} ({fp_rate*100:.2f}%)")
        print(f"  æ£€æµ‹ç‡: {detection_rate:.4f} ({detection_rate*100:.2f}%)")
        
        # ROC AUC
        test_proba = model.predict_proba(X_test)[:, 1]
        auc_score = roc_auc_score(y_test, test_proba)
        print(f"  ROC AUC: {auc_score:.4f}")
        
        # äº¤å‰éªŒè¯
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')
        print(f"  äº¤å‰éªŒè¯F1: {cv_scores.mean():.4f} (Â±{cv_scores.std()*2:.4f})")
    
    def _analyze_feature_importance(self, model):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        print("\nğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ:")
        
        importances = model.feature_importances_
        feature_importance_df = pd.DataFrame({
            'feature': self.feature_names[1:],  # å»æ‰æ–‡ä»¶å
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        # Top 20 é‡è¦ç‰¹å¾
        print("Top 20 é‡è¦ç‰¹å¾:")
        for i, (_, row) in enumerate(feature_importance_df.head(20).iterrows(), 1):
            print(f"  {i:2d}. {row['feature']}: {row['importance']:.4f}")
        
        # åˆ†æç‰¹å¾ç±»å‹
        obfuscation_imp = feature_importance_df[
            feature_importance_df['feature'].str.startswith('FEATURE_')
        ]['importance'].mean()
        
        suspicious_imp = feature_importance_df[
            feature_importance_df['feature'].str.startswith('SUSPICIOUS_')
        ]['importance'].mean()
        
        benign_imp = feature_importance_df[
            feature_importance_df['feature'].str.startswith('BENIGN_')
        ]['importance'].mean()
        
        print(f"\nğŸ“Š ç‰¹å¾ç±»å‹å¹³å‡é‡è¦æ€§:")
        print(f"  æ··æ·†ç‰¹å¾: {obfuscation_imp:.4f}")
        print(f"  å¯ç–‘ç‰¹å¾: {suspicious_imp:.4f}")
        print(f"  è‰¯æ€§ç‰¹å¾: {benign_imp:.4f}")
        
        return feature_importance_df
    
    def save_models(self, output_dir='models_enhanced'):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜Random Forestæ¨¡å‹
        if 'RandomForest' in self.models:
            model_path = output_dir / 'randomforest_enhanced_model.pkl'
            with open(model_path, 'wb') as f:
                pickle.dump(self.models['RandomForest'], f)
            print(f"âœ… Random Forestæ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # ä¿å­˜ç‰¹å¾åç§°
        if self.feature_names:
            feature_path = output_dir / 'enhanced_feature_columns.pkl'
            with open(feature_path, 'wb') as f:
                pickle.dump(self.feature_names, f)
            print(f"âœ… ç‰¹å¾åç§°å·²ä¿å­˜: {feature_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºç‰ˆRandom Forestè®­ç»ƒå™¨")
    print("=" * 50)
    
    trainer = EnhancedRFTrainer()
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X, y = trainer.prepare_training_data('data/good250623', 'data/bad250623')
    
    if X is None:
        print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥")
        return
    
    # è®­ç»ƒæ¨¡å‹
    rf_model = trainer.train_enhanced_rf(X, y, optimize_params=False)
    
    # ä¿å­˜æ¨¡å‹
    trainer.save_models()
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    print("ğŸ’¡ å»ºè®®:")
    print("  1. ä½¿ç”¨æ–°æ¨¡å‹æµ‹è¯•è¯¯æŠ¥ç‡")
    print("  2. è°ƒæ•´åˆ†ç±»é˜ˆå€¼è¿›ä¸€æ­¥ä¼˜åŒ–")
    print("  3. æ”¶é›†æ›´å¤šè‰¯æ€§æ ·æœ¬è¿›è¡Œè®­ç»ƒ")

if __name__ == "__main__":
    main()
