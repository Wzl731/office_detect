#!/usr/bin/env python3
"""
è®­ç»ƒVBAæ¶æ„å®æ£€æµ‹æ¨¡å‹å¹¶ä¿å­˜
åŸºäºåŸå§‹é¡¹ç›®çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè®­ç»ƒåä¿å­˜åˆ°modelsæ–‡ä»¶å¤¹
"""

import numpy as np
import pandas as pd
import pickle
import os
import argparse
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# åŠ¨æ€å¯¼å…¥ç‰¹å¾æå–æ¨¡å—
def import_feature_extractor(module_name='feature222'):
    """åŠ¨æ€å¯¼å…¥ç‰¹å¾æå–æ¨¡å—"""
    try:
        if module_name == 'original':
            from original_feature_extractor import OriginalVBAFeatureExtractor
        elif module_name == 'feature222':
            from feature222 import OriginalVBAFeatureExtractor
        elif module_name == 'feature_11111':
            from feature_11111 import OriginalVBAFeatureExtractor
        else:
            raise ImportError(f"æœªçŸ¥çš„ç‰¹å¾æå–æ¨¡å—: {module_name}")

        print(f"âœ… æˆåŠŸå¯¼å…¥ç‰¹å¾æå–æ¨¡å—: {module_name}")
        return OriginalVBAFeatureExtractor
    except ImportError as e:
        print(f"âŒ å¯¼å…¥ç‰¹å¾æå–æ¨¡å—å¤±è´¥: {e}")
        return None


class DatasetProcessor:
    """æ•°æ®é›†å¤„ç†å™¨ - è´Ÿè´£ç‰¹å¾æå–å’Œæ•°æ®é›†ç”Ÿæˆ"""

    def __init__(self, feature_extractor_name='feature222'):
        """åˆå§‹åŒ–æ•°æ®é›†å¤„ç†å™¨"""
        self.feature_extractor_class = import_feature_extractor(feature_extractor_name)
        if self.feature_extractor_class is None:
            raise RuntimeError("ç‰¹å¾æå–æ¨¡å—å¯¼å…¥å¤±è´¥")

        self.extractor = self.feature_extractor_class()

    def extract_features_from_folder(self, folder_path, label, output_file=None):
        """ä»æ–‡ä»¶å¤¹æå–ç‰¹å¾å¹¶ä¿å­˜"""
        folder_path = Path(folder_path)

        if not folder_path.exists():
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
            return None

        # è·å–æ‰€æœ‰æ–‡ä»¶
        files = [f for f in folder_path.iterdir() if f.is_file()]
        if not files:
            print(f"âŒ æ–‡ä»¶å¤¹ä¸ºç©º: {folder_path}")
            return None

        print(f"ğŸ“ å¤„ç†æ–‡ä»¶å¤¹: {folder_path} (æ ‡ç­¾: {'æ¶æ„' if label == 1 else 'è‰¯æ€§'})")
        print(f"ğŸ“„ æ–‡ä»¶æ•°é‡: {len(files)}")

        features_list = []
        successful_count = 0

        for i, file_path in enumerate(files, 1):
            if i % 100 == 0:
                print(f"  å¤„ç†è¿›åº¦: {i}/{len(files)}")

            try:
                # æå–ç‰¹å¾
                features = self.extractor.extract_features_from_file(file_path)
                if features is not None:
                    # æ·»åŠ æ ‡ç­¾
                    features.append(label)
                    features_list.append(features)
                    successful_count += 1
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥ {file_path.name}: {e}")

        print(f"âœ… æˆåŠŸå¤„ç†: {successful_count}/{len(files)} ä¸ªæ–‡ä»¶")

        if not features_list:
            print("âŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾")
            return None

        # è½¬æ¢ä¸ºDataFrame
        feature_names = self.extractor.get_feature_names() + ['label']
        df = pd.DataFrame(features_list, columns=feature_names)

        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            df.to_excel(output_path, index=False)
            print(f"ğŸ’¾ ç‰¹å¾æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")

        return df

    def process_datasets(self, benign_folder, malicious_folder, output_file='processed_dataset.xls'):
        """å¤„ç†è‰¯æ€§å’Œæ¶æ„æ•°æ®é›†"""
        print("ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®é›†...")

        # å¤„ç†è‰¯æ€§æ ·æœ¬
        benign_df = self.extract_features_from_folder(benign_folder, label=0)
        if benign_df is None:
            return None

        # å¤„ç†æ¶æ„æ ·æœ¬
        malicious_df = self.extract_features_from_folder(malicious_folder, label=1)
        if malicious_df is None:
            return None

        # åˆå¹¶æ•°æ®é›†
        combined_df = pd.concat([benign_df, malicious_df], ignore_index=True)

        # ä¿å­˜åˆå¹¶åçš„æ•°æ®é›†
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        combined_df.to_excel(output_path, index=False)

        print(f"âœ… æ•°æ®é›†å¤„ç†å®Œæˆ:")
        print(f"  ğŸ“Š è‰¯æ€§æ ·æœ¬: {len(benign_df)}")
        print(f"  ğŸ“Š æ¶æ„æ ·æœ¬: {len(malicious_df)}")
        print(f"  ğŸ“Š æ€»æ ·æœ¬æ•°: {len(combined_df)}")
        print(f"  ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")

        return combined_df

class VBAMalwareModelTrainer:
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹è®­ç»ƒå™¨"""
        self.models = {}
        self.scalers = {}
        self.feature_columns = None
        
        # æ•°æ®é›†é…ç½®
        self.DS1_BENIGN_SAMPLES_CNT = 2939
        self.DS1_MAL_SAMPLES_CNT = 13734
        
        # æ¨¡å‹é…ç½® 
        # TODO ä¼˜åŒ–å‚æ•°ä»¥æé«˜æ€§èƒ½ 
        self.model_configs = {
            'RandomForest': {
                'model': RandomForestClassifier(
                    n_estimators=100,
                    random_state=42,
                    n_jobs=-1
                ),
                'need_scaling': False
            },
            'MLP': {
                'model': MLPClassifier(
                    hidden_layer_sizes=(150,),
                    max_iter=2000,  # å¢åŠ è¿­ä»£æ¬¡æ•°
                    alpha=1e-4,
                    learning_rate='adaptive',
                    early_stopping=True,  # æ—©åœ
                    validation_fraction=0.1,
                    random_state=42
                ),
                'need_scaling': True
            },
            'KNN': {
                'model': KNeighborsClassifier(
                    n_neighbors=3,
                    weights='distance',  # ä½¿ç”¨è·ç¦»æƒé‡
                    n_jobs=-1
                ),
                'need_scaling': True
            },
            'SVM': {
                'model': SVC(
                    kernel='rbf',  # ä½¿ç”¨RBFæ ¸
                    C=1.0,
                    gamma='scale',
                    random_state=42,
                    probability=True
                ),
                'need_scaling': True
            }
        }
    
    def load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        print("ğŸ“Š åŠ è½½æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®é›†1
        try:
            self.dataset1 = pd.read_excel('ds1.xls')
            print(f"  âœ… æ•°æ®é›†1åŠ è½½æˆåŠŸ: {len(self.dataset1)} æ¡è®°å½•")
        except Exception as e:
            print(f"  âŒ æ•°æ®é›†1åŠ è½½å¤±è´¥: {e}")
            return False
        
        # åˆ›å»ºæ ‡ç­¾
        self.labels = [0] * self.DS1_BENIGN_SAMPLES_CNT + [1] * self.DS1_MAL_SAMPLES_CNT
        
        # ä¿å­˜ç‰¹å¾åˆ—å
        self.feature_columns = self.dataset1.columns[1:124].tolist()  # æ’é™¤æ–‡ä»¶ååˆ—
        
        print(f"  ğŸ“‹ ç‰¹å¾ç»´åº¦: {len(self.feature_columns)}")
        print(f"  ğŸ“‹ è‰¯æ€§æ ·æœ¬: {self.DS1_BENIGN_SAMPLES_CNT}")
        print(f"  ğŸ“‹ æ¶æ„æ ·æœ¬: {self.DS1_MAL_SAMPLES_CNT}")
        
        return True
    
    def prepare_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        X = self.dataset1.iloc[:, 1:124].values  # 123ç»´ç‰¹å¾
        y = np.array(self.labels)
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"  ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(self.X_train)}")
        print(f"  ğŸ“Š æµ‹è¯•é›†å¤§å°: {len(self.X_test)}")
        
        return True
    
    def train_models(self):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        for model_name, config in self.model_configs.items():
            print(f"\n   è®­ç»ƒ {model_name} æ¨¡å‹...")
            
            try:
                model = config['model']
                
                # å‡†å¤‡è®­ç»ƒæ•°æ®
                X_train = self.X_train.copy()
                X_test = self.X_test.copy()
                
                # å¦‚æœéœ€è¦æ ‡å‡†åŒ–
                if config['need_scaling']:
                    scaler = StandardScaler()
                    X_train = scaler.fit_transform(X_train)
                    X_test = scaler.transform(X_test)
                    self.scalers[model_name] = scaler
                    print(f"    âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")
                
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train, self.y_train)
                
                # è¯„ä¼°æ¨¡å‹
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(self.y_test, y_pred)
                
                print(f"    âœ… {model_name} è®­ç»ƒå®Œæˆ")
                print(f"    ğŸ“ˆ æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
                
                # ä¿å­˜æ¨¡å‹
                self.models[model_name] = model
                
            except Exception as e:
                print(f"    âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
    
    def save_models(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        
        # åˆ›å»ºmodelsç›®å½•
        models_dir = Path('models')
        models_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ¯ä¸ªæ¨¡å‹
        for model_name, model in self.models.items():
            try:
                # ä¿å­˜æ¨¡å‹
                model_path = models_dir / f'{model_name.lower()}_model.pkl'
                with open(model_path, 'wb') as f:
                    pickle.dump(model, f)
                print(f"  âœ… {model_name} æ¨¡å‹å·²ä¿å­˜: {model_path}")
                
                # ä¿å­˜å¯¹åº”çš„æ ‡å‡†åŒ–å™¨ï¼ˆå¦‚æœæœ‰ï¼‰
                if model_name in self.scalers:
                    scaler_path = models_dir / f'{model_name.lower()}_scaler.pkl'
                    with open(scaler_path, 'wb') as f:
                        pickle.dump(self.scalers[model_name], f)
                    print(f"  âœ… {model_name} æ ‡å‡†åŒ–å™¨å·²ä¿å­˜: {scaler_path}")
                    
            except Exception as e:
                print(f"  âŒ ä¿å­˜ {model_name} å¤±è´¥: {e}")
        
        # ä¿å­˜ç‰¹å¾åˆ—å
        try:
            feature_path = models_dir / 'feature_columns.pkl'
            with open(feature_path, 'wb') as f:
                pickle.dump(self.feature_columns, f)
            print(f"  âœ… ç‰¹å¾åˆ—åå·²ä¿å­˜: {feature_path}")
        except Exception as e:
            print(f"  âŒ ä¿å­˜ç‰¹å¾åˆ—åå¤±è´¥: {e}")
    
    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„æ¨¡å‹è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæ¨¡å‹è¯„ä¼°æŠ¥å‘Š...")
        
        report_path = Path('models') / 'model_evaluation_report.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("VBAæ¶æ„å®æ£€æµ‹æ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ•°æ®é›†ä¿¡æ¯:\n")
            f.write(f"  - æ€»æ ·æœ¬æ•°: {len(self.dataset1)}\n")
            f.write(f"  - è‰¯æ€§æ ·æœ¬: {self.DS1_BENIGN_SAMPLES_CNT}\n")
            f.write(f"  - æ¶æ„æ ·æœ¬: {self.DS1_MAL_SAMPLES_CNT}\n")
            f.write(f"  - ç‰¹å¾ç»´åº¦: {len(self.feature_columns)}\n\n")
            
            for model_name, model in self.models.items():
                f.write(f"{model_name} æ¨¡å‹è¯„ä¼°:\n")
                f.write("-" * 30 + "\n")
                
                try:
                    # å‡†å¤‡æµ‹è¯•æ•°æ®
                    X_test = self.X_test.copy()
                    if model_name in self.scalers:
                        X_test = self.scalers[model_name].transform(X_test)
                    
                    # é¢„æµ‹
                    y_pred = model.predict(X_test)
                    accuracy = accuracy_score(self.y_test, y_pred)
                    
                    f.write(f"å‡†ç¡®ç‡: {accuracy:.4f}\n")
                    f.write(f"åˆ†ç±»æŠ¥å‘Š:\n{classification_report(self.y_test, y_pred)}\n")
                    f.write(f"æ··æ·†çŸ©é˜µ:\n{confusion_matrix(self.y_test, y_pred)}\n\n")
                    
                except Exception as e:
                    f.write(f"è¯„ä¼°å¤±è´¥: {e}\n\n")
        
        print(f"  âœ… è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def run(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        print("ğŸ¯ VBAæ¶æ„å®æ£€æµ‹æ¨¡å‹è®­ç»ƒå™¨")
        print("=" * 50)
        
        # åŠ è½½æ•°æ®é›†
        if not self.load_dataset():
            return False
        
        # å‡†å¤‡æ•°æ®
        if not self.prepare_data():
            return False
        
        # è®­ç»ƒæ¨¡å‹
        self.train_models()
        
        # ä¿å­˜æ¨¡å‹
        self.save_models()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_detailed_report()
        
        print("\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: ./models/")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    trainer = VBAMalwareModelTrainer()
    success = trainer.run()
    
    if success:
        print("\nâœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå¹¶ä¿å­˜æˆåŠŸï¼")
    else:
        print("\nâŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼")

if __name__ == "__main__":
    main()

#python detector.py --no-save
#python detector.py --save-type benign
#python detector.py --save-type malicious