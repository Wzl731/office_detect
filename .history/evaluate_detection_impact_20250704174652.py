#!/usr/bin/env python3
"""
è¯„ä¼°æ™ºèƒ½åå¤„ç†è§„åˆ™å¯¹æ¶æ„æ–‡ä»¶æ£€æµ‹ç‡çš„å½±å“
"""

import sys
import os
from pathlib import Path
import pandas as pd

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

try:
    from rules import get_post_processing_rules, apply_post_processing
    from original_feature_extractor import extract_features
    import joblib
    import numpy as np
    POST_PROCESSOR_AVAILABLE = True
    print("âœ… åå¤„ç†è§„åˆ™æ¨¡å—å·²åŠ è½½")
except ImportError as e:
    POST_PROCESSOR_AVAILABLE = False
    print(f"âŒ åå¤„ç†è§„åˆ™æ¨¡å—åŠ è½½å¤±è´¥: {e}")

def test_sample_files(folder_path, max_files=20):
    """æµ‹è¯•æ ·æœ¬æ–‡ä»¶ï¼Œæ¯”è¾ƒåŸå§‹é¢„æµ‹å’Œåå¤„ç†ç»“æœ"""
    
    if not POST_PROCESSOR_AVAILABLE:
        print("âŒ åå¤„ç†æ¨¡å—ä¸å¯ç”¨")
        return
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = VBAMalwareDetector(use_post_processing=False)  # å…ˆä¸ä½¿ç”¨åå¤„ç†
    if not detector.load_models():
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        return
    
    # è·å–è§„åˆ™
    rules = get_post_processing_rules()
    if not rules.is_available():
        print("âŒ è§„åˆ™ä¸å¯ç”¨")
        return
    
    folder = Path(folder_path)
    if not folder.exists():
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}")
        return
    
    # è·å–æ–‡ä»¶åˆ—è¡¨
    files = []
    for ext in ['*.doc', '*.docx', '*.xls', '*.xlsx', '*.ppt', '*.pptx']:
        files.extend(folder.glob(ext))
    
    files = files[:max_files]  # é™åˆ¶æ–‡ä»¶æ•°é‡
    
    print(f"ğŸ” æµ‹è¯• {len(files)} ä¸ªæ–‡ä»¶...")
    print("=" * 80)
    
    results = []
    
    for i, file_path in enumerate(files, 1):
        print(f"\n[{i}/{len(files)}] ğŸ“„ {file_path.name}")
        
        try:
            # æå–ç‰¹å¾
            features = extract_features(str(file_path))
            if features is None:
                print("  âŒ ç‰¹å¾æå–å¤±è´¥")
                continue
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            features_dict = {}
            for j, feature_name in enumerate(detector.feature_names):
                features_dict[feature_name] = features[j] if j < len(features) else 0
            
            # RandomForeståŸå§‹é¢„æµ‹
            rf_model = detector.models['RandomForest']
            rf_prob = rf_model.predict_proba([features])[0]
            rf_malicious_prob = rf_prob[1]
            rf_prediction = 1 if rf_malicious_prob > 0.5 else 0
            
            # åº”ç”¨åå¤„ç†
            post_result = apply_post_processing(
                features_dict, rf_prediction, rf_malicious_prob
            )
            
            # è®°å½•ç»“æœ
            result = {
                'file': file_path.name,
                'original_prediction': rf_prediction,
                'original_probability': rf_malicious_prob,
                'adjusted_prediction': post_result['adjusted_prediction'],
                'adjusted_probability': post_result['adjusted_probability'],
                'confidence_level': post_result['confidence_level'],
                'risk_factors': len(post_result['risk_factors']),
                'protective_factors': len(post_result['protective_factors']),
                'changed': rf_prediction != post_result['adjusted_prediction']
            }
            results.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            print(f"  ğŸ¤– åŸå§‹: {'æ¶æ„' if rf_prediction else 'è‰¯æ€§'} ({rf_malicious_prob:.3f})")
            print(f"  ğŸ§  è°ƒæ•´: {'æ¶æ„' if post_result['adjusted_prediction'] else 'è‰¯æ€§'} ({post_result['adjusted_probability']:.3f})")
            print(f"  ğŸ“Š ç½®ä¿¡åº¦: {post_result['confidence_level']}")
            print(f"  ğŸš¨ é£é™©å› ç´ : {len(post_result['risk_factors'])}")
            print(f"  ğŸ›¡ï¸  ä¿æŠ¤å› ç´ : {len(post_result['protective_factors'])}")
            
            if result['changed']:
                print(f"  âš ï¸  é¢„æµ‹æ”¹å˜: {'æ¶æ„â†’è‰¯æ€§' if rf_prediction else 'è‰¯æ€§â†’æ¶æ„'}")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
    
    # ç»Ÿè®¡åˆ†æ
    if results:
        print(f"\n{'='*80}")
        print("ğŸ“Š ç»Ÿè®¡åˆ†æ")
        print(f"{'='*80}")
        
        total = len(results)
        changed_count = sum(1 for r in results if r['changed'])
        malicious_to_benign = sum(1 for r in results if r['original_prediction'] == 1 and r['adjusted_prediction'] == 0)
        benign_to_malicious = sum(1 for r in results if r['original_prediction'] == 0 and r['adjusted_prediction'] == 1)
        
        original_malicious = sum(1 for r in results if r['original_prediction'] == 1)
        adjusted_malicious = sum(1 for r in results if r['adjusted_prediction'] == 1)
        
        print(f"ğŸ“ˆ æ€»æ–‡ä»¶æ•°: {total}")
        print(f"ğŸ”„ é¢„æµ‹æ”¹å˜: {changed_count} ({changed_count/total*100:.1f}%)")
        print(f"ğŸ“‰ æ¶æ„â†’è‰¯æ€§: {malicious_to_benign} ({malicious_to_benign/total*100:.1f}%)")
        print(f"ğŸ“ˆ è‰¯æ€§â†’æ¶æ„: {benign_to_malicious} ({benign_to_malicious/total*100:.1f}%)")
        print(f"ğŸ¯ åŸå§‹æ¶æ„æ£€å‡º: {original_malicious}/{total} ({original_malicious/total*100:.1f}%)")
        print(f"ğŸ¯ è°ƒæ•´åæ¶æ„æ£€å‡º: {adjusted_malicious}/{total} ({adjusted_malicious/total*100:.1f}%)")
        
        if original_malicious > 0:
            detection_rate_change = (adjusted_malicious - original_malicious) / original_malicious * 100
            print(f"ğŸ“Š æ£€æµ‹ç‡å˜åŒ–: {detection_rate_change:+.1f}%")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        df = pd.DataFrame(results)
        df.to_csv('detection_impact_analysis.csv', index=False)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: detection_impact_analysis.csv")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æ™ºèƒ½åå¤„ç†è§„åˆ™å¯¹æ¶æ„æ–‡ä»¶æ£€æµ‹ç‡å½±å“è¯„ä¼°")
    print("=" * 80)
    
    # æµ‹è¯•æ¶æ„æ–‡ä»¶
    print("\nğŸ¦  æµ‹è¯•æ¶æ„æ–‡ä»¶ (data/bad250623):")
    test_sample_files('data/bad250623', max_files=30)
    
    # æµ‹è¯•è‰¯æ€§æ–‡ä»¶
    print("\nğŸŸ¢ æµ‹è¯•è‰¯æ€§æ–‡ä»¶ (data/good250623):")
    test_sample_files('data/good250623', max_files=30)

if __name__ == "__main__":
    main()
