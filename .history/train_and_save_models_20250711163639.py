#!/usr/bin/env python3
"""
è®­ç»ƒVBAæ¶æ„å®æ£€æµ‹æ¨¡å‹å¹¶ä¿å­˜
åŸºäºåŸå§‹é¡¹ç›®çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè®­ç»ƒåä¿å­˜åˆ°modelsæ–‡ä»¶å¤¹
"""

import numpy as np
import pandas as pd
import pickle
import os
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

class VBAMalwareModelTrainer:
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹è®­ç»ƒå™¨"""
        self.models = {}
        self.scalers = {}
        self.feature_columns = None
        
        # æ•°æ®é›†é…ç½®
        self.DS1_BENIGN_SAMPLES_CNT = 2939
        self.DS1_MAL_SAMPLES_CNT = 13734
        
        # æ¨¡å‹é…ç½® 
        # TODO ä¼˜åŒ–å‚æ•°ä»¥æé«˜æ€§èƒ½ 
        self.model_configs = {
            'RandomForest': {
                'model': RandomForestClassifier(
                    n_estimators=100,
                    random_state=42,
                    n_jobs=-1
                ),
                'need_scaling': False
            },
            'MLP': {
                'model': MLPClassifier(
                    hidden_layer_sizes=(150,),
                    max_iter=2000,  # å¢åŠ è¿­ä»£æ¬¡æ•°
                    alpha=1e-4,
                    learning_rate='adaptive',
                    early_stopping=True,  # æ—©åœ
                    validation_fraction=0.1,
                    random_state=42
                ),
                'need_scaling': True
            },
            'KNN': {
                'model': KNeighborsClassifier(
                    n_neighbors=3,
                    weights='distance',  # ä½¿ç”¨è·ç¦»æƒé‡
                    n_jobs=-1
                ),
                'need_scaling': True
            },
            'SVM': {
                'model': SVC(
                    kernel='rbf',  # ä½¿ç”¨RBFæ ¸
                    C=1.0,
                    gamma='scale',
                    random_state=42,
                    probability=True
                ),
                'need_scaling': True
            }
        }
    
    def load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        print("ğŸ“Š åŠ è½½æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®é›†1
        try:
            self.dataset1 = pd.read_excel('ds1.xls')
            print(f"  âœ… æ•°æ®é›†1åŠ è½½æˆåŠŸ: {len(self.dataset1)} æ¡è®°å½•")
        except Exception as e:
            print(f"  âŒ æ•°æ®é›†1åŠ è½½å¤±è´¥: {e}")
            return False
        
        # åˆ›å»ºæ ‡ç­¾
        self.labels = [0] * self.DS1_BENIGN_SAMPLES_CNT + [1] * self.DS1_MAL_SAMPLES_CNT
        
        # ä¿å­˜ç‰¹å¾åˆ—å
        self.feature_columns = self.dataset1.columns[1:124].tolist()  # æ’é™¤æ–‡ä»¶ååˆ—
        
        print(f"  ğŸ“‹ ç‰¹å¾ç»´åº¦: {len(self.feature_columns)}")
        print(f"  ğŸ“‹ è‰¯æ€§æ ·æœ¬: {self.DS1_BENIGN_SAMPLES_CNT}")
        print(f"  ğŸ“‹ æ¶æ„æ ·æœ¬: {self.DS1_MAL_SAMPLES_CNT}")
        
        return True
    
    def prepare_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        X = self.dataset1.iloc[:, 1:124].values  # 123ç»´ç‰¹å¾
        y = np.array(self.labels)
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"  ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(self.X_train)}")
        print(f"  ğŸ“Š æµ‹è¯•é›†å¤§å°: {len(self.X_test)}")
        
        return True
    
    def train_models(self):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        for model_name, config in self.model_configs.items():
            print(f"\n   è®­ç»ƒ {model_name} æ¨¡å‹...")
            
            try:
                model = config['model']
                
                # å‡†å¤‡è®­ç»ƒæ•°æ®
                X_train = self.X_train.copy()
                X_test = self.X_test.copy()
                
                # å¦‚æœéœ€è¦æ ‡å‡†åŒ–
                if config['need_scaling']:
                    scaler = StandardScaler()
                    X_train = scaler.fit_transform(X_train)
                    X_test = scaler.transform(X_test)
                    self.scalers[model_name] = scaler
                    print(f"    âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")
                
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train, self.y_train)
                
                # è¯„ä¼°æ¨¡å‹
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(self.y_test, y_pred)
                
                print(f"    âœ… {model_name} è®­ç»ƒå®Œæˆ")
                print(f"    ğŸ“ˆ æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
                
                # ä¿å­˜æ¨¡å‹
                self.models[model_name] = model
                
            except Exception as e:
                print(f"    âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
    
    def save_models(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        
        # åˆ›å»ºmodelsç›®å½•
        models_dir = Path('models')
        models_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜æ¯ä¸ªæ¨¡å‹
        for model_name, model in self.models.items():
            try:
                # ä¿å­˜æ¨¡å‹
                model_path = models_dir / f'{model_name.lower()}_model.pkl'
                with open(model_path, 'wb') as f:
                    pickle.dump(model, f)
                print(f"  âœ… {model_name} æ¨¡å‹å·²ä¿å­˜: {model_path}")
                
                # ä¿å­˜å¯¹åº”çš„æ ‡å‡†åŒ–å™¨ï¼ˆå¦‚æœæœ‰ï¼‰
                if model_name in self.scalers:
                    scaler_path = models_dir / f'{model_name.lower()}_scaler.pkl'
                    with open(scaler_path, 'wb') as f:
                        pickle.dump(self.scalers[model_name], f)
                    print(f"  âœ… {model_name} æ ‡å‡†åŒ–å™¨å·²ä¿å­˜: {scaler_path}")
                    
            except Exception as e:
                print(f"  âŒ ä¿å­˜ {model_name} å¤±è´¥: {e}")
        
        # ä¿å­˜ç‰¹å¾åˆ—å
        try:
            feature_path = models_dir / 'feature_columns.pkl'
            with open(feature_path, 'wb') as f:
                pickle.dump(self.feature_columns, f)
            print(f"  âœ… ç‰¹å¾åˆ—åå·²ä¿å­˜: {feature_path}")
        except Exception as e:
            print(f"  âŒ ä¿å­˜ç‰¹å¾åˆ—åå¤±è´¥: {e}")
    
    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„æ¨¡å‹è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæ¨¡å‹è¯„ä¼°æŠ¥å‘Š...")
        
        report_path = Path('models') / 'model_evaluation_report.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("VBAæ¶æ„å®æ£€æµ‹æ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ•°æ®é›†ä¿¡æ¯:\n")
            f.write(f"  - æ€»æ ·æœ¬æ•°: {len(self.dataset1)}\n")
            f.write(f"  - è‰¯æ€§æ ·æœ¬: {self.DS1_BENIGN_SAMPLES_CNT}\n")
            f.write(f"  - æ¶æ„æ ·æœ¬: {self.DS1_MAL_SAMPLES_CNT}\n")
            f.write(f"  - ç‰¹å¾ç»´åº¦: {len(self.feature_columns)}\n\n")
            
            for model_name, model in self.models.items():
                f.write(f"{model_name} æ¨¡å‹è¯„ä¼°:\n")
                f.write("-" * 30 + "\n")
                
                try:
                    # å‡†å¤‡æµ‹è¯•æ•°æ®
                    X_test = self.X_test.copy()
                    if model_name in self.scalers:
                        X_test = self.scalers[model_name].transform(X_test)
                    
                    # é¢„æµ‹
                    y_pred = model.predict(X_test)
                    accuracy = accuracy_score(self.y_test, y_pred)
                    
                    f.write(f"å‡†ç¡®ç‡: {accuracy:.4f}\n")
                    f.write(f"åˆ†ç±»æŠ¥å‘Š:\n{classification_report(self.y_test, y_pred)}\n")
                    f.write(f"æ··æ·†çŸ©é˜µ:\n{confusion_matrix(self.y_test, y_pred)}\n\n")
                    
                except Exception as e:
                    f.write(f"è¯„ä¼°å¤±è´¥: {e}\n\n")
        
        print(f"  âœ… è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    def run(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        print("ğŸ¯ VBAæ¶æ„å®æ£€æµ‹æ¨¡å‹è®­ç»ƒå™¨")
        print("=" * 50)
        
        # åŠ è½½æ•°æ®é›†
        if not self.load_dataset():
            return False
        
        # å‡†å¤‡æ•°æ®
        if not self.prepare_data():
            return False
        
        # è®­ç»ƒæ¨¡å‹
        self.train_models()
        
        # ä¿å­˜æ¨¡å‹
        self.save_models()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_detailed_report()
        
        print("\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: ./models/")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    trainer = VBAMalwareModelTrainer()
    success = trainer.run()
    
    if success:
        print("\nâœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå¹¶ä¿å­˜æˆåŠŸï¼")
    else:
        print("\nâŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼")

if __name__ == "__main__":
    main()

#python detector.py --no-save
#python detector.py --save-type benign
#python detector.py --save-type malicious