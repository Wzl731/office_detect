#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•æ¶æ„æ ·æœ¬çš„æ£€æµ‹æ•ˆæœ
"""

import sys
import os
from pathlib import Path
import glob

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

try:
    from rules import get_post_processing_rules, apply_post_processing
    from original_feature_extractor import OriginalVBAFeatureExtractor
    import joblib
    import numpy as np
    POST_PROCESSOR_AVAILABLE = True
    print("âœ… åå¤„ç†è§„åˆ™æ¨¡å—å·²åŠ è½½")
except ImportError as e:
    POST_PROCESSOR_AVAILABLE = False
    print(f"âŒ åå¤„ç†è§„åˆ™æ¨¡å—åŠ è½½å¤±è´¥: {e}")

def test_malicious_samples(folder_path, max_files=20):
    """æµ‹è¯•æ¶æ„æ ·æœ¬"""
    
    if not POST_PROCESSOR_AVAILABLE:
        print("âŒ åå¤„ç†æ¨¡å—ä¸å¯ç”¨")
        return
    
    # åŠ è½½RandomForestæ¨¡å‹
    try:
        rf_model = joblib.load('models/RandomForest_model.pkl')
        print("âœ… RandomForestæ¨¡å‹å·²åŠ è½½")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½ç‰¹å¾åç§°
    try:
        with open('models/feature_names.txt', 'r') as f:
            feature_names = [line.strip() for line in f.readlines()]
        print(f"âœ… ç‰¹å¾åç§°å·²åŠ è½½ ({len(feature_names)} ä¸ª)")
    except Exception as e:
        print(f"âŒ ç‰¹å¾åç§°åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
    try:
        extractor = VBAFeatureExtractor()
        print("âœ… ç‰¹å¾æå–å™¨å·²åˆå§‹åŒ–")
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # è·å–è§„åˆ™
    rules = get_post_processing_rules()
    if not rules.is_available():
        print("âŒ è§„åˆ™ä¸å¯ç”¨")
        return
    
    # è·å–æ–‡ä»¶åˆ—è¡¨
    folder = Path(folder_path)
    if not folder.exists():
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder}")
        return
    
    # è·å–æ¶æ„æ–‡ä»¶
    files = []
    for ext in ['*.doc', '*.docx', '*.xls', '*.xlsx']:
        files.extend(folder.glob(ext))
    
    files = files[:max_files]  # é™åˆ¶æ–‡ä»¶æ•°é‡
    
    print(f"\nğŸ¦  æµ‹è¯•æ¶æ„æ ·æœ¬: {len(files)} ä¸ªæ–‡ä»¶")
    print("=" * 80)
    
    results = {
        'original_malicious': 0,
        'adjusted_malicious': 0,
        'malicious_to_benign': 0,
        'benign_to_malicious': 0,
        'total_files': 0,
        'failed_files': 0
    }
    
    for i, file_path in enumerate(files, 1):
        print(f"\n[{i}/{len(files)}] ğŸ“„ {file_path.name}")
        
        try:
            # æå–ç‰¹å¾
            features = extractor.extract_features_from_file(str(file_path))
            if features is None:
                print("  âŒ ç‰¹å¾æå–å¤±è´¥")
                results['failed_files'] += 1
                continue
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            features_dict = {}
            for j, feature_name in enumerate(feature_names):
                features_dict[feature_name] = features[j] if j < len(features) else 0
            
            # RandomForeståŸå§‹é¢„æµ‹
            rf_prob = rf_model.predict_proba([features])[0]
            rf_malicious_prob = rf_prob[1]
            rf_prediction = 1 if rf_malicious_prob > 0.5 else 0
            
            # åº”ç”¨åå¤„ç†
            post_result = apply_post_processing(
                features_dict, rf_prediction, rf_malicious_prob
            )
            
            # ç»Ÿè®¡ç»“æœ
            results['total_files'] += 1
            if rf_prediction == 1:
                results['original_malicious'] += 1
            if post_result['adjusted_prediction'] == 1:
                results['adjusted_malicious'] += 1
            
            if rf_prediction == 1 and post_result['adjusted_prediction'] == 0:
                results['malicious_to_benign'] += 1
                print("  âš ï¸  æ¶æ„â†’è‰¯æ€§ (å¯èƒ½çš„æ¼æŠ¥)")
            elif rf_prediction == 0 and post_result['adjusted_prediction'] == 1:
                results['benign_to_malicious'] += 1
                print("  ğŸ“ˆ è‰¯æ€§â†’æ¶æ„")
            
            # æ˜¾ç¤ºç»“æœ
            print(f"  ğŸ¤– åŸå§‹: {'æ¶æ„' if rf_prediction else 'è‰¯æ€§'} ({rf_malicious_prob:.3f})")
            print(f"  ğŸ§  è°ƒæ•´: {'æ¶æ„' if post_result['adjusted_prediction'] else 'è‰¯æ€§'} ({post_result['adjusted_probability']:.3f})")
            print(f"  ğŸ“Š ç½®ä¿¡åº¦: {post_result['confidence_level']}")
            
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            results['failed_files'] += 1
    
    # ç»Ÿè®¡åˆ†æ
    print(f"\n{'='*80}")
    print("ğŸ“Š æ¶æ„æ ·æœ¬æ£€æµ‹ç»“æœç»Ÿè®¡")
    print(f"{'='*80}")
    
    total_processed = results['total_files']
    if total_processed > 0:
        original_detection_rate = results['original_malicious'] / total_processed * 100
        adjusted_detection_rate = results['adjusted_malicious'] / total_processed * 100
        
        print(f"ğŸ“ˆ å¤„ç†æ–‡ä»¶æ•°: {total_processed}")
        print(f"âŒ å¤±è´¥æ–‡ä»¶æ•°: {results['failed_files']}")
        print(f"ğŸ¯ åŸå§‹æ£€æµ‹ç‡: {results['original_malicious']}/{total_processed} ({original_detection_rate:.1f}%)")
        print(f"ğŸ¯ è°ƒæ•´åæ£€æµ‹ç‡: {results['adjusted_malicious']}/{total_processed} ({adjusted_detection_rate:.1f}%)")
        print(f"ğŸ“‰ æ¶æ„â†’è‰¯æ€§: {results['malicious_to_benign']} ä¸ª (æ½œåœ¨æ¼æŠ¥)")
        print(f"ğŸ“ˆ è‰¯æ€§â†’æ¶æ„: {results['benign_to_malicious']} ä¸ª")
        
        detection_rate_change = adjusted_detection_rate - original_detection_rate
        print(f"ğŸ“Š æ£€æµ‹ç‡å˜åŒ–: {detection_rate_change:+.1f}%")
        
        if results['malicious_to_benign'] > 0:
            miss_rate = results['malicious_to_benign'] / results['original_malicious'] * 100 if results['original_malicious'] > 0 else 0
            print(f"âš ï¸  æ¼æŠ¥ç‡: {miss_rate:.1f}% ({results['malicious_to_benign']}/{results['original_malicious']})")
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¦  æ¶æ„æ ·æœ¬æ£€æµ‹æ•ˆæœæµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•æ¶æ„æ–‡ä»¶
    results = test_malicious_samples('data/bad250623', max_files=30)
    
    if results and results['total_files'] > 0:
        print(f"\nğŸ’¡ åˆ†æç»“è®º:")
        print("=" * 60)
        
        if results['malicious_to_benign'] > 0:
            print(f"âš ï¸  æ™ºèƒ½åå¤„ç†ç¡®å®é™ä½äº†å¯¹æ¶æ„æ–‡ä»¶çš„æ£€æµ‹ç‡")
            print(f"   åŸå› : {results['malicious_to_benign']} ä¸ªæ¶æ„æ–‡ä»¶è¢«è¯¯åˆ¤ä¸ºè‰¯æ€§")
            print(f"   å»ºè®®: éœ€è¦è°ƒæ•´åå¤„ç†è§„åˆ™çš„é˜ˆå€¼æˆ–æ¡ä»¶")
        else:
            print(f"âœ… æ™ºèƒ½åå¤„ç†æ²¡æœ‰å½±å“æ¶æ„æ–‡ä»¶çš„æ£€æµ‹")
        
        if results['adjusted_malicious'] > results['original_malicious']:
            print(f"ğŸ“ˆ åå¤„ç†è¿˜æé«˜äº† {results['benign_to_malicious']} ä¸ªæ–‡ä»¶çš„æ£€æµ‹")

if __name__ == "__main__":
    main()
